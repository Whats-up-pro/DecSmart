{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3fc32ef",
   "metadata": {},
   "source": [
    "# üéØ High-Fidelity GraphSAGE (HiFi-GraphSAGE) for Smart Contract Vulnerability Detection\n",
    "\n",
    "## Methodology Overview\n",
    "\n",
    "This notebook implements the **HiFi-GraphSAGE** framework following the research methodology:\n",
    "\n",
    "### Pipeline Architecture:\n",
    "1. **Solidity Source Code** ‚Üí Compilation ‚Üí **EVM Bytecode**\n",
    "2. **EVM Bytecode** ‚Üí Disassembly ‚Üí **Opcode Sequence**\n",
    "3. **Opcode Sequence** ‚Üí Basic Block Identification ‚Üí **High-Fidelity CFG**\n",
    "4. **HF-CFG** ‚Üí Node Feature Extraction (Opcode Embeddings) ‚Üí **Graph Data**\n",
    "5. **Graph Data** ‚Üí GraphSAGE Model ‚Üí **Vulnerability Classification**\n",
    "\n",
    "### Key Components:\n",
    "- **High-Fidelity Control Flow Graph (HF-CFG)**: Preserves semantic content of EVM opcodes\n",
    "- **Opcode Embeddings**: Word2Vec/FastText for opcode semantics\n",
    "- **GraphSAGE (Graph Sample and Aggregate)**: Inductive learning for vulnerability detection\n",
    "\n",
    "### Datasets:\n",
    "- **ESC Dataset**: 307,396 functions from 40,932 Ethereum smart contracts\n",
    "  - 5,013 functions with call.value (Re-entrancy vulnerability)\n",
    "  - 4,833 functions with block.timestamp (Timestamp dependence vulnerability)\n",
    "- **VSC Dataset**: 13,761 functions from 4,170 VNT Chain smart contracts\n",
    "  - 2,925 functions with loop statements\n",
    "\n",
    "### Target Vulnerabilities:\n",
    "- **Re-entrancy** (call.value)\n",
    "- **Timestamp Dependence** (block.timestamp)\n",
    "- **Loop Statements** (VSC dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05678b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a18eb8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ pyevmasm available for EVM disassembly\n",
      "‚úÖ gensim available for opcode embeddings\n",
      "\n",
      "‚úÖ PyTorch: 2.9.0+cu126\n",
      "‚úÖ Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: INSTALL DEPENDENCIES\n",
    "# =============================================================================\n",
    "!pip install -q torch-geometric pyevmasm gensim\n",
    "!pip install -q pandas scikit-learn matplotlib seaborn tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import io\n",
    "import json  # Th√™m json ƒë·ªÉ parse dataset\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool, global_max_pool, global_add_pool\n",
    "from torch_geometric.data import Batch\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Try to import pyevmasm for EVM disassembly\n",
    "try:\n",
    "    from pyevmasm import disassemble_all, disassemble_one\n",
    "    PYEVMASM_AVAILABLE = True\n",
    "    print(\"‚úÖ pyevmasm available for EVM disassembly\")\n",
    "except ImportError:\n",
    "    PYEVMASM_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è pyevmasm not available, using regex-based bytecode analysis\")\n",
    "\n",
    "# Try to import gensim for Word2Vec embeddings\n",
    "try:\n",
    "    from gensim.models import Word2Vec\n",
    "    GENSIM_AVAILABLE = True\n",
    "    print(\"‚úÖ gensim available for opcode embeddings\")\n",
    "except ImportError:\n",
    "    GENSIM_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è gensim not available, using one-hot encoding\")\n",
    "\n",
    "# Seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96404066",
   "metadata": {},
   "source": [
    "## 2. Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "703574c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "‚öôÔ∏è CONFIGURATION - HiFi-GraphSAGE METHODOLOGY\n",
      "================================================================================\n",
      "\n",
      "üìã Configuration Summary:\n",
      "   Dataset: VSC\n",
      "   Target Vulnerabilities: ['No Loop', 'Has Loop']\n",
      "   Node Features: 164 (150 BoW + 14 semantic)\n",
      "   Remove TIMESTAMP Feature: True (Feature 12 removed)\n",
      "   \n",
      "   Model Architecture (GraphSAGE):\n",
      "   - Hidden Channels: 32\n",
      "   - GraphSAGE Layers: 2\n",
      "   - Dropout: 0.6\n",
      "   \n",
      "   Training (Adam Optimizer):\n",
      "   - Learning Rate: 0.0003\n",
      "   - Weight Decay: 0.002\n",
      "   - Batch Size: 64\n",
      "   - Epochs: 100\n",
      "   \n",
      "   Threshold: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: CONFIGURATION\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"‚öôÔ∏è CONFIGURATION - HiFi-GraphSAGE METHODOLOGY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Directories\n",
    "BASE_DIR = \".\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"hifi_graphsage\")\n",
    "MODEL_SAVE_DIR = os.path.join(BASE_DIR, \"saved_models\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Dataset Selection: 'ESC' or 'VSC'\n",
    "DATASET_NAME = 'VSC'  # Changed to 'VSC' to use VNT Chain dataset from GNNSCVulDetector\n",
    "\n",
    "# Target Vulnerabilities (ESC Dataset)\n",
    "# ESC: Re-entrancy (call.value), Timestamp Dependence (block.timestamp)\n",
    "# VSC: Loop Statements\n",
    "if DATASET_NAME == 'ESC':\n",
    "    TARGET_VULNS = ['Re-entrancy', 'Timestamp Dependence']\n",
    "    VULN_LABELS = {'Re-entrancy': 0, 'Timestamp Dependence': 1}\n",
    "    NUM_CLASSES = 2\n",
    "elif DATASET_NAME == 'VSC':\n",
    "    TARGET_VULNS = ['No Loop', 'Has Loop']\n",
    "    VULN_LABELS = {'No Loop': 0, 'Has Loop': 1}\n",
    "    NUM_CLASSES = 2\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset: {DATASET_NAME}\")\n",
    "\n",
    "# EVM Opcode Vocabulary (for High-Fidelity feature extraction)\n",
    "EVM_OPCODES = {\n",
    "    # Arithmetic\n",
    "    'STOP': 0, 'ADD': 1, 'MUL': 2, 'SUB': 3, 'DIV': 4, 'SDIV': 5, 'MOD': 6, \n",
    "    'SMOD': 7, 'ADDMOD': 8, 'MULMOD': 9, 'EXP': 10, 'SIGNEXTEND': 11,\n",
    "    # Comparison\n",
    "    'LT': 12, 'GT': 13, 'SLT': 14, 'SGT': 15, 'EQ': 16, 'ISZERO': 17,\n",
    "    # Bitwise\n",
    "    'AND': 18, 'OR': 19, 'XOR': 20, 'NOT': 21, 'BYTE': 22, 'SHL': 23, 'SHR': 24, 'SAR': 25,\n",
    "    # Hash\n",
    "    'SHA3': 26, 'KECCAK256': 26,\n",
    "    # Environment\n",
    "    'ADDRESS': 27, 'BALANCE': 28, 'ORIGIN': 29, 'CALLER': 30, 'CALLVALUE': 31,\n",
    "    'CALLDATALOAD': 32, 'CALLDATASIZE': 33, 'CALLDATACOPY': 34, 'CODESIZE': 35,\n",
    "    'CODECOPY': 36, 'GASPRICE': 37, 'EXTCODESIZE': 38, 'EXTCODECOPY': 39,\n",
    "    'RETURNDATASIZE': 40, 'RETURNDATACOPY': 41, 'EXTCODEHASH': 42,\n",
    "    # Block\n",
    "    'BLOCKHASH': 43, 'COINBASE': 44, 'TIMESTAMP': 45, 'NUMBER': 46, \n",
    "    'DIFFICULTY': 47, 'GASLIMIT': 48, 'CHAINID': 49, 'SELFBALANCE': 50, 'BASEFEE': 51,\n",
    "    # Stack/Memory/Storage\n",
    "    'POP': 52, 'MLOAD': 53, 'MSTORE': 54, 'MSTORE8': 55, 'SLOAD': 56, 'SSTORE': 57,\n",
    "    # Control Flow\n",
    "    'JUMP': 58, 'JUMPI': 59, 'PC': 60, 'MSIZE': 61, 'GAS': 62, 'JUMPDEST': 63,\n",
    "    # Push operations (64-95)\n",
    "    'PUSH1': 64, 'PUSH2': 65, 'PUSH32': 95,\n",
    "    # Dup operations (96-111)\n",
    "    'DUP1': 96, 'DUP16': 111,\n",
    "    # Swap operations (112-127)\n",
    "    'SWAP1': 112, 'SWAP16': 127,\n",
    "    # Log operations\n",
    "    'LOG0': 128, 'LOG1': 129, 'LOG2': 130, 'LOG3': 131, 'LOG4': 132,\n",
    "    # System\n",
    "    'CREATE': 133, 'CALL': 134, 'CALLCODE': 135, 'RETURN': 136,\n",
    "    'DELEGATECALL': 137, 'CREATE2': 138, 'STATICCALL': 139,\n",
    "    'REVERT': 140, 'INVALID': 141, 'SELFDESTRUCT': 142,\n",
    "}\n",
    "VOCAB_SIZE = 150  # Total opcode vocabulary size\n",
    "\n",
    "# Feature Selection: Lo·∫°i b·ªè TIMESTAMP feature ƒë·ªÉ tr√°nh overfitting khi train c√°c l·ªó h·ªïng kh√°c\n",
    "# Set True ƒë·ªÉ lo·∫°i b·ªè feature 12 (TIMESTAMP) - Khuy·∫øn ngh·ªã khi train Re-entrancy ho·∫∑c c√°c l·ªó h·ªïng kh√°c\n",
    "REMOVE_TIMESTAMP_FEATURE = True  # Set False n·∫øu mu·ªën gi·ªØ feature TIMESTAMP\n",
    "\n",
    "# High-Fidelity Feature Dimensions\n",
    "# 150 (BoW opcode counts) + 15 (semantic features) = 165 total\n",
    "# N·∫øu REMOVE_TIMESTAMP_FEATURE = True: 150 + 14 = 164 total\n",
    "NUM_BOW_FEATURES = 150\n",
    "NUM_SEMANTIC_FEATURES = 15 if not REMOVE_TIMESTAMP_FEATURE else 14\n",
    "NUM_NODE_FEATURES = NUM_BOW_FEATURES + NUM_SEMANTIC_FEATURES\n",
    "\n",
    "# Model Architecture (GraphSAGE) - Gi·∫£m capacity ƒë·ªÉ ch·ªëng overfitting\n",
    "HIDDEN_CHANNELS = 32      # Reduced from 64 to prevent overfitting\n",
    "NUM_SAGE_LAYERS = 2       # Number of GraphSAGE layers\n",
    "DROPOUT = 0.6             # Increased dropout to prevent overfitting (was 0.5)\n",
    "\n",
    "# Training Hyperparameters (Using Adam with standard settings)\n",
    "LEARNING_RATE = 3e-4      # Further reduced learning rate (was 5e-4)\n",
    "WEIGHT_DECAY = 2e-3       # Further increased weight decay (was 1e-3)\n",
    "BATCH_SIZE = 64           # Increased batch size for more stable training\n",
    "EPOCHS = 100              # Reduced from 200\n",
    "PATIENCE = 10             # More aggressive early stopping (was 15)\n",
    "\n",
    "# Class Weights (Simplified - equal weights)\n",
    "CLASS_WEIGHT_0 = 1.0    # Equal weight for class 0\n",
    "CLASS_WEIGHT_1 = 1.0    # Equal weight for class 1\n",
    "\n",
    "# Thresholds\n",
    "THRESHOLD = 0.5       # Default threshold\n",
    "\n",
    "print(f\"\"\"\n",
    "üìã Configuration Summary:\n",
    "   Dataset: {DATASET_NAME}\n",
    "   Target Vulnerabilities: {TARGET_VULNS}\n",
    "   Node Features: {NUM_NODE_FEATURES} ({NUM_BOW_FEATURES} BoW + {NUM_SEMANTIC_FEATURES} semantic)\n",
    "   Remove TIMESTAMP Feature: {REMOVE_TIMESTAMP_FEATURE} {'(Feature 12 removed)' if REMOVE_TIMESTAMP_FEATURE else '(Feature 12 included)'}\n",
    "   \n",
    "   Model Architecture (GraphSAGE):\n",
    "   - Hidden Channels: {HIDDEN_CHANNELS}\n",
    "   - GraphSAGE Layers: {NUM_SAGE_LAYERS}\n",
    "   - Dropout: {DROPOUT}\n",
    "   \n",
    "   Training (Adam Optimizer):\n",
    "   - Learning Rate: {LEARNING_RATE}\n",
    "   - Weight Decay: {WEIGHT_DECAY}\n",
    "   - Batch Size: {BATCH_SIZE}\n",
    "   - Epochs: {EPOCHS}\n",
    "   \n",
    "   Threshold: {THRESHOLD}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b10b51",
   "metadata": {},
   "source": [
    "## 3. High-Fidelity Control Flow Graph (HF-CFG) Builder\n",
    "\n",
    "The HF-CFG is constructed through:\n",
    "1. **Disassembly**: Raw EVM bytecode ‚Üí Opcode sequence\n",
    "2. **Basic Block Identification**: Partition into basic blocks (single entry, single exit)\n",
    "3. **Graph Construction**: Nodes = basic blocks, Edges = control flow transitions\n",
    "4. **High-Fidelity Feature Extraction**: \n",
    "   - Bag-of-Opcodes (150 dims)\n",
    "   - Semantic features (15 dims) for vulnerability patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4011fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîß HIGH-FIDELITY CONTROL FLOW GRAPH (HF-CFG) BUILDER\n",
      "================================================================================\n",
      "‚úÖ HiFi-CFG Builder initialized\n",
      "   - BoW features: 150\n",
      "   - Semantic features: 14\n",
      "   - ‚ö†Ô∏è Feature 12 (TIMESTAMP) ƒë√£ ƒë∆∞·ª£c lo·∫°i b·ªè ƒë·ªÉ tr√°nh overfitting\n",
      "   - Total node features: 164\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: HIGH-FIDELITY CFG BUILDER\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üîß HIGH-FIDELITY CONTROL FLOW GRAPH (HF-CFG) BUILDER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class HiFiCFGBuilder:\n",
    "    \"\"\"\n",
    "    High-Fidelity Control Flow Graph Builder\n",
    "    \n",
    "    Implements the methodology:\n",
    "    1. Disassembly: EVM bytecode ‚Üí opcode sequence\n",
    "    2. Basic Block Identification\n",
    "    3. Graph Construction with control flow edges\n",
    "    4. High-Fidelity Feature Extraction (BoW + Semantic)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, remove_timestamp_feature=False):\n",
    "        self.opcode_vocab = EVM_OPCODES\n",
    "        self.vocab_size = VOCAB_SIZE\n",
    "        self.remove_timestamp_feature = remove_timestamp_feature\n",
    "        self.num_semantic = NUM_SEMANTIC_FEATURES\n",
    "        self.total_features = NUM_NODE_FEATURES\n",
    "        \n",
    "        # Terminator opcodes for basic block splitting\n",
    "        self.terminators = {'JUMP', 'JUMPI', 'STOP', 'RETURN', 'REVERT', 'INVALID', 'SELFDESTRUCT'}\n",
    "        \n",
    "        # Vulnerability-relevant opcodes\n",
    "        self.reentrancy_opcodes = {'CALL', 'CALLCODE', 'DELEGATECALL', 'STATICCALL'}\n",
    "        self.arithmetic_opcodes = {'ADD', 'SUB', 'MUL', 'DIV', 'EXP', 'ADDMOD', 'MULMOD'}\n",
    "        self.storage_opcodes = {'SLOAD', 'SSTORE'}\n",
    "        self.dangerous_opcodes = {'SELFDESTRUCT', 'ORIGIN', 'DELEGATECALL'}\n",
    "    \n",
    "    def disassemble_bytecode(self, bytecode_hex):\n",
    "        \"\"\"\n",
    "        Disassemble EVM bytecode into opcode sequence\n",
    "        Returns list of instruction objects or tuples (name, operand, pc)\n",
    "        \"\"\"\n",
    "        if bytecode_hex.startswith(\"0x\"):\n",
    "            bytecode_hex = bytecode_hex[2:]\n",
    "        \n",
    "        # Clean bytecode\n",
    "        bytecode_hex = ''.join(c for c in bytecode_hex if c in '0123456789abcdefABCDEF')\n",
    "        \n",
    "        if len(bytecode_hex) < 2:\n",
    "            return []\n",
    "        \n",
    "        if PYEVMASM_AVAILABLE:\n",
    "            try:\n",
    "                bytecode = bytes.fromhex(bytecode_hex)\n",
    "                instructions = list(disassemble_all(bytecode))\n",
    "                return instructions\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Fallback: Simple regex-based parsing\n",
    "        return self._simple_disassemble(bytecode_hex)\n",
    "    \n",
    "    def _simple_disassemble(self, bytecode_hex):\n",
    "        \"\"\"Simple bytecode parsing without pyevmasm\"\"\"\n",
    "        instructions = []\n",
    "        \n",
    "        # Common opcode patterns in bytecode\n",
    "        opcode_patterns = {\n",
    "            'f1': 'CALL', 'f2': 'CALLCODE', 'f4': 'DELEGATECALL', 'fa': 'STATICCALL',\n",
    "            '54': 'SLOAD', '55': 'SSTORE',\n",
    "            '01': 'ADD', '02': 'MUL', '03': 'SUB', '04': 'DIV', '0a': 'EXP',\n",
    "            '56': 'JUMP', '57': 'JUMPI', '5b': 'JUMPDEST',\n",
    "            '00': 'STOP', 'f3': 'RETURN', 'fd': 'REVERT', 'ff': 'SELFDESTRUCT',\n",
    "            '34': 'CALLVALUE', '32': 'ORIGIN', '33': 'CALLER',\n",
    "            '42': 'TIMESTAMP', '43': 'NUMBER',\n",
    "            '20': 'SHA3', '10': 'LT', '11': 'GT', '14': 'EQ', '15': 'ISZERO',\n",
    "        }\n",
    "        \n",
    "        i = 0\n",
    "        pc = 0\n",
    "        while i < len(bytecode_hex) - 1:\n",
    "            opcode = bytecode_hex[i:i+2].lower()\n",
    "            \n",
    "            # Check if it's a PUSH instruction\n",
    "            if opcode.startswith('6') or opcode.startswith('7'):\n",
    "                push_size = int(opcode, 16) - 0x5f\n",
    "                instructions.append(('PUSH' + str(push_size), bytecode_hex[i+2:i+2+push_size*2], pc))\n",
    "                i += 2 + push_size * 2\n",
    "                pc += 1 + push_size\n",
    "            elif opcode in opcode_patterns:\n",
    "                instructions.append((opcode_patterns[opcode], '', pc))\n",
    "                i += 2\n",
    "                pc += 1\n",
    "            else:\n",
    "                i += 2\n",
    "                pc += 1\n",
    "        \n",
    "        return instructions\n",
    "    \n",
    "    def build_cfg(self, bytecode_or_instructions):\n",
    "        \"\"\"\n",
    "        Build High-Fidelity Control Flow Graph\n",
    "        \n",
    "        Returns: nx.DiGraph with basic blocks as nodes\n",
    "        \"\"\"\n",
    "        # Get instructions\n",
    "        if isinstance(bytecode_or_instructions, str):\n",
    "            instructions = self.disassemble_bytecode(bytecode_or_instructions)\n",
    "        else:\n",
    "            instructions = bytecode_or_instructions\n",
    "        \n",
    "        if not instructions:\n",
    "            return nx.DiGraph()\n",
    "        \n",
    "        cfg = nx.DiGraph()\n",
    "        blocks = []\n",
    "        current_block = []\n",
    "        pc_to_block_idx = {}\n",
    "        \n",
    "        # Partition into basic blocks\n",
    "        for instr in instructions:\n",
    "            # Handle both pyevmasm objects and tuples\n",
    "            if hasattr(instr, 'name'):\n",
    "                name = instr.name\n",
    "                pc = instr.pc\n",
    "            else:\n",
    "                name, _, pc = instr\n",
    "            \n",
    "            # Start new block at JUMPDEST\n",
    "            if name == 'JUMPDEST' and current_block:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "            \n",
    "            current_block.append(instr)\n",
    "            \n",
    "            # End block at terminators\n",
    "            if name in self.terminators:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "        \n",
    "        if current_block:\n",
    "            blocks.append(current_block)\n",
    "        \n",
    "        # Add nodes with features\n",
    "        for idx, block in enumerate(blocks):\n",
    "            if not block:\n",
    "                continue\n",
    "            \n",
    "            # Get start PC\n",
    "            if hasattr(block[0], 'pc'):\n",
    "                start_pc = block[0].pc\n",
    "            else:\n",
    "                start_pc = block[0][2]\n",
    "            \n",
    "            pc_to_block_idx[start_pc] = idx\n",
    "            cfg.add_node(idx, instructions=block, start_pc=start_pc)\n",
    "        \n",
    "        # Add edges based on control flow\n",
    "        for idx, block in enumerate(blocks):\n",
    "            if not block:\n",
    "                continue\n",
    "            \n",
    "            # Get last instruction\n",
    "            last_instr = block[-1]\n",
    "            if hasattr(last_instr, 'name'):\n",
    "                last_name = last_instr.name\n",
    "            else:\n",
    "                last_name = last_instr[0]\n",
    "            \n",
    "            # Fallthrough edge (if not a terminal jump)\n",
    "            if last_name not in {'STOP', 'RETURN', 'REVERT', 'INVALID', 'SELFDESTRUCT', 'JUMP'}:\n",
    "                if idx + 1 < len(blocks):\n",
    "                    cfg.add_edge(idx, idx + 1, type='fallthrough')\n",
    "            \n",
    "            # Jump edges\n",
    "            if last_name in {'JUMP', 'JUMPI'}:\n",
    "                target_pc = self._resolve_jump_target(block)\n",
    "                if target_pc is not None and target_pc in pc_to_block_idx:\n",
    "                    target_idx = pc_to_block_idx[target_pc]\n",
    "                    cfg.add_edge(idx, target_idx, type='jump')\n",
    "                \n",
    "                # For JUMPI, also add fallthrough edge\n",
    "                if last_name == 'JUMPI' and idx + 1 < len(blocks):\n",
    "                    cfg.add_edge(idx, idx + 1, type='fallthrough')\n",
    "        \n",
    "        return cfg\n",
    "    \n",
    "    def _resolve_jump_target(self, block):\n",
    "        \"\"\"Resolve jump target from PUSH instruction before JUMP\"\"\"\n",
    "        if len(block) >= 2:\n",
    "            prev_instr = block[-2]\n",
    "            if hasattr(prev_instr, 'name'):\n",
    "                name = prev_instr.name\n",
    "                operand = prev_instr.operand if hasattr(prev_instr, 'operand') else None\n",
    "            else:\n",
    "                name, operand, _ = prev_instr\n",
    "            \n",
    "            if name.startswith('PUSH'):\n",
    "                try:\n",
    "                    if isinstance(operand, str):\n",
    "                        return int(operand, 16) if operand else None\n",
    "                    elif isinstance(operand, int):\n",
    "                        return operand\n",
    "                except:\n",
    "                    pass\n",
    "        return None\n",
    "    \n",
    "    def extract_block_features(self, block):\n",
    "        \"\"\"\n",
    "        Extract High-Fidelity features for a basic block\n",
    "        \n",
    "        Returns: numpy array of shape (NUM_NODE_FEATURES,)\n",
    "        - First 150 dims: Bag-of-Opcodes (opcode frequency)\n",
    "        - Last 15 dims: Semantic features for vulnerability detection\n",
    "        \"\"\"\n",
    "        # Part 1: Bag-of-Opcodes (150 dims)\n",
    "        bow_vec = np.zeros(self.vocab_size)\n",
    "        \n",
    "        for instr in block:\n",
    "            if hasattr(instr, 'name'):\n",
    "                name = instr.name\n",
    "            else:\n",
    "                name = instr[0]\n",
    "            \n",
    "            # Get opcode index\n",
    "            if name in self.opcode_vocab:\n",
    "                idx = self.opcode_vocab[name]\n",
    "            elif name.startswith('PUSH'):\n",
    "                idx = self.opcode_vocab.get('PUSH1', 64)\n",
    "            elif name.startswith('DUP'):\n",
    "                idx = self.opcode_vocab.get('DUP1', 96)\n",
    "            elif name.startswith('SWAP'):\n",
    "                idx = self.opcode_vocab.get('SWAP1', 112)\n",
    "            elif name.startswith('LOG'):\n",
    "                idx = self.opcode_vocab.get('LOG0', 128)\n",
    "            else:\n",
    "                idx = self.vocab_size - 1  # Unknown\n",
    "            \n",
    "            if idx < self.vocab_size:\n",
    "                bow_vec[idx] += 1\n",
    "        \n",
    "        # Normalize BoW\n",
    "        if bow_vec.sum() > 0:\n",
    "            bow_vec = bow_vec / bow_vec.sum()\n",
    "        \n",
    "        # Part 2: Semantic Features - for vulnerability detection\n",
    "        # Size depends on whether timestamp feature is removed\n",
    "        semantic_vec = np.zeros(self.num_semantic)\n",
    "        \n",
    "        opcode_names = []\n",
    "        for instr in block:\n",
    "            if hasattr(instr, 'name'):\n",
    "                opcode_names.append(instr.name)\n",
    "            else:\n",
    "                opcode_names.append(instr[0])\n",
    "        \n",
    "        # Feature 0: Block size (normalized)\n",
    "        semantic_vec[0] = min(len(block) / 50.0, 1.0)\n",
    "        \n",
    "        # Feature 1: Has external calls (CALL, DELEGATECALL, etc.) - Re-entrancy\n",
    "        semantic_vec[1] = 1.0 if any(op in self.reentrancy_opcodes for op in opcode_names) else 0.0\n",
    "        \n",
    "        # Feature 2: Has storage operations (SLOAD, SSTORE) - State changes\n",
    "        semantic_vec[2] = 1.0 if any(op in self.storage_opcodes for op in opcode_names) else 0.0\n",
    "        \n",
    "        # Feature 3: Has dangerous patterns (SELFDESTRUCT, ORIGIN)\n",
    "        semantic_vec[3] = 1.0 if any(op in self.dangerous_opcodes for op in opcode_names) else 0.0\n",
    "        \n",
    "        # Feature 4: Has conditionals (JUMPI) - Control flow complexity\n",
    "        semantic_vec[4] = 1.0 if 'JUMPI' in opcode_names else 0.0\n",
    "        \n",
    "        # Feature 5: Has arithmetic operations - Overflow/Underflow\n",
    "        semantic_vec[5] = 1.0 if any(op in self.arithmetic_opcodes for op in opcode_names) else 0.0\n",
    "        \n",
    "        # Feature 6: Arithmetic operation count (normalized) - Overflow risk\n",
    "        arith_count = sum(1 for op in opcode_names if op in self.arithmetic_opcodes)\n",
    "        semantic_vec[6] = min(arith_count / 10.0, 1.0)\n",
    "        \n",
    "        # Feature 7: CALLVALUE present - Ether handling\n",
    "        semantic_vec[7] = 1.0 if 'CALLVALUE' in opcode_names else 0.0\n",
    "        \n",
    "        # Feature 8: Has CREATE/CREATE2 - Contract creation\n",
    "        semantic_vec[8] = 1.0 if any(op in {'CREATE', 'CREATE2'} for op in opcode_names) else 0.0\n",
    "        \n",
    "        # Feature 9: CALL before SSTORE pattern - Re-entrancy indicator\n",
    "        call_idx = next((i for i, op in enumerate(opcode_names) if op in self.reentrancy_opcodes), -1)\n",
    "        sstore_idx = next((i for i, op in enumerate(opcode_names) if op == 'SSTORE'), -1)\n",
    "        semantic_vec[9] = 1.0 if (call_idx >= 0 and sstore_idx > call_idx) else 0.0\n",
    "        \n",
    "        # Feature 10: Complexity ratio (PUSH to total)\n",
    "        push_count = sum(1 for op in opcode_names if op.startswith('PUSH'))\n",
    "        semantic_vec[10] = push_count / max(len(block), 1)\n",
    "        \n",
    "        # Feature 11: Has comparison operations (for overflow checks)\n",
    "        comparison_ops = {'LT', 'GT', 'SLT', 'SGT', 'EQ', 'ISZERO'}\n",
    "        semantic_vec[11] = 1.0 if any(op in comparison_ops for op in opcode_names) else 0.0\n",
    "        \n",
    "        # Feature 12: Has timestamp/block number - Timestamp dependency\n",
    "        # Skip this feature if REMOVE_TIMESTAMP_FEATURE is True\n",
    "        if not self.remove_timestamp_feature:\n",
    "            time_ops = {'TIMESTAMP', 'NUMBER', 'BLOCKHASH'}\n",
    "            semantic_vec[12] = 1.0 if any(op in time_ops for op in opcode_names) else 0.0\n",
    "            # Feature 13: Balance check - Reentrancy context\n",
    "            semantic_vec[13] = 1.0 if 'BALANCE' in opcode_names else 0.0\n",
    "            # Feature 14: Gas operations - DoS patterns\n",
    "            semantic_vec[14] = 1.0 if 'GAS' in opcode_names else 0.0\n",
    "        else:\n",
    "            # When timestamp feature is removed, shift indices\n",
    "            # Feature 12 (now index 12): Balance check - Reentrancy context\n",
    "            semantic_vec[12] = 1.0 if 'BALANCE' in opcode_names else 0.0\n",
    "            # Feature 13 (now index 13): Gas operations - DoS patterns\n",
    "            semantic_vec[13] = 1.0 if 'GAS' in opcode_names else 0.0\n",
    "        \n",
    "        # Combine BoW and Semantic features\n",
    "        return np.concatenate([bow_vec, semantic_vec])\n",
    "    \n",
    "    def cfg_to_pyg_data(self, cfg):\n",
    "        \"\"\"\n",
    "        Convert NetworkX CFG to PyTorch Geometric Data object\n",
    "        \"\"\"\n",
    "        if cfg.number_of_nodes() == 0:\n",
    "            return None\n",
    "        \n",
    "        # Extract node features\n",
    "        node_features = []\n",
    "        node_mapping = {node: i for i, node in enumerate(cfg.nodes())}\n",
    "        \n",
    "        for node_id in cfg.nodes():\n",
    "            block = cfg.nodes[node_id].get('instructions', [])\n",
    "            features = self.extract_block_features(block)\n",
    "            node_features.append(features)\n",
    "        \n",
    "        x = torch.tensor(np.array(node_features), dtype=torch.float)\n",
    "        \n",
    "        # Extract edges\n",
    "        edge_indices = []\n",
    "        for src, dst in cfg.edges():\n",
    "            edge_indices.append([node_mapping[src], node_mapping[dst]])\n",
    "        \n",
    "        if not edge_indices:\n",
    "            # Add self-loop if no edges\n",
    "            edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "        else:\n",
    "            edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Initialize CFG Builder with feature selection\n",
    "cfg_builder = HiFiCFGBuilder(remove_timestamp_feature=REMOVE_TIMESTAMP_FEATURE)\n",
    "print(f\"‚úÖ HiFi-CFG Builder initialized\")\n",
    "print(f\"   - BoW features: {NUM_BOW_FEATURES}\")\n",
    "print(f\"   - Semantic features: {NUM_SEMANTIC_FEATURES}\")\n",
    "if REMOVE_TIMESTAMP_FEATURE:\n",
    "    print(f\"   - ‚ö†Ô∏è Feature 12 (TIMESTAMP) ƒë√£ ƒë∆∞·ª£c lo·∫°i b·ªè ƒë·ªÉ tr√°nh overfitting\")\n",
    "print(f\"   - Total node features: {NUM_NODE_FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a7a5a3",
   "metadata": {},
   "source": [
    "## 4. Bytecode Generation from Solidity Source\n",
    "\n",
    "Since SolidiFI provides Solidity source, we generate synthetic bytecode patterns based on vulnerability type. In production, this would use solc compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "785fa512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# H√ÄM ƒê·ªÇ LOAD DATASET TH·∫¨T ESC/VSC (N·∫øu c√≥)\n",
    "# =============================================================================\n",
    "def load_esc_dataset_real():\n",
    "    \"\"\"\n",
    "    Load REAL ESC Dataset t·ª´ file th·∫≠t (n·∫øu c√≥)\n",
    "    \n",
    "    C·∫ßn format:\n",
    "    - File ch·ª©a bytecode c·ªßa contracts\n",
    "    - Labels cho t·ª´ng contract\n",
    "    - Metadata (has_callvalue, has_timestamp, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        List of contracts v·ªõi format gi·ªëng load_esc_dataset()\n",
    "    \"\"\"\n",
    "    esc_data_path = os.path.join(DATA_DIR, \"esc_dataset\")\n",
    "    \n",
    "    # Ki·ªÉm tra xem c√≥ file dataset th·∫≠t kh√¥ng\n",
    "    if not os.path.exists(esc_data_path):\n",
    "        print(\"   ‚ö†Ô∏è Dataset th·∫≠t kh√¥ng t√¨m th·∫•y, s·ª≠ d·ª•ng synthetic data\")\n",
    "        return None\n",
    "    \n",
    "    contracts = []\n",
    "    # TODO: Implement logic ƒë·ªÉ load t·ª´ file th·∫≠t\n",
    "    # V√≠ d·ª•:\n",
    "    # - ƒê·ªçc file JSON/CSV ch·ª©a bytecode v√† labels\n",
    "    # - Parse v√† convert sang format c·∫ßn thi·∫øt\n",
    "    \n",
    "    return contracts\n",
    "\n",
    "def load_vsc_dataset_real():\n",
    "    \"\"\"\n",
    "    Load REAL VSC Dataset t·ª´ file th·∫≠t (n·∫øu c√≥)\n",
    "    \"\"\"\n",
    "    vsc_data_path = os.path.join(DATA_DIR, \"vsc_dataset\")\n",
    "    \n",
    "    if not os.path.exists(vsc_data_path):\n",
    "        print(\"   ‚ö†Ô∏è Dataset th·∫≠t kh√¥ng t√¨m th·∫•y, s·ª≠ d·ª•ng synthetic data\")\n",
    "        return None\n",
    "    \n",
    "    contracts = []\n",
    "    # TODO: Implement logic ƒë·ªÉ load t·ª´ file th·∫≠t\n",
    "    \n",
    "    return contracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "241934f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üì• LOADING DATA - VSC Dataset\n",
      "================================================================================\n",
      "   üì• Loading VSC Dataset (VNT Chain Smart Contracts)...\n",
      "   üí° ƒêang s·ª≠ d·ª•ng synthetic data cho demo\n",
      "   ‚úÖ Generated 5000 VSC samples\n",
      "\n",
      "   ‚úÖ Loaded 5000 contracts from VSC dataset\n",
      "\n",
      "   üìä Distribution:\n",
      "      Has Loop: 2500 (50.00%)\n",
      "      No Loop: 2500 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: DATA LOADING - ESC v√† VSC Datasets\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(f\"üì• LOADING DATA - {DATASET_NAME} Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "SOLIDIFI_URL = \"https://github.com/DependableSystemsLab/SolidiFI-benchmark/archive/refs/heads/master.zip\"\n",
    "SOLIDIFI_DIR = os.path.join(DATA_DIR, \"SolidiFI-benchmark\")\n",
    "\n",
    "def download_solidifi():\n",
    "    \"\"\"Download SolidiFI-benchmark\"\"\"\n",
    "    if os.path.exists(SOLIDIFI_DIR):\n",
    "        print(\"   ‚úÖ SolidiFI-benchmark already exists\")\n",
    "        return True\n",
    "    \n",
    "    print(\"   üì• Downloading SolidiFI-benchmark...\")\n",
    "    try:\n",
    "        response = urllib.request.urlopen(SOLIDIFI_URL, timeout=180)\n",
    "        with zipfile.ZipFile(io.BytesIO(response.read())) as z:\n",
    "            z.extractall(DATA_DIR)\n",
    "        \n",
    "        extracted = os.path.join(DATA_DIR, \"SolidiFI-benchmark-master\")\n",
    "        if os.path.exists(extracted):\n",
    "            import shutil\n",
    "            if os.path.exists(SOLIDIFI_DIR):\n",
    "                shutil.rmtree(SOLIDIFI_DIR)\n",
    "            os.rename(extracted, SOLIDIFI_DIR)\n",
    "        \n",
    "        print(\"   ‚úÖ Downloaded successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Download failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def generate_bytecode_from_source(source_code, vuln_type):\n",
    "    \"\"\"\n",
    "    Generate synthetic bytecode patterns from Solidity source code.\n",
    "    Preserves vulnerability patterns in bytecode representation.\n",
    "    \n",
    "    In production, this would use: solc -> bytecode -> pyevmasm\n",
    "    \"\"\"\n",
    "    bytecode = \"6080604052\"  # Standard Solidity header\n",
    "    source_lower = source_code.lower()\n",
    "    \n",
    "    # =============== OVERFLOW-UNDERFLOW PATTERNS ===============\n",
    "    if vuln_type == 'Overflow-Underflow':\n",
    "        # Arithmetic operations without SafeMath\n",
    "        if '+' in source_code or 'add' in source_lower:\n",
    "            bytecode += \"01\"  # ADD\n",
    "        if '-' in source_code or 'sub' in source_lower:\n",
    "            bytecode += \"03\"  # SUB\n",
    "        if '*' in source_code or 'mul' in source_lower:\n",
    "            bytecode += \"02\"  # MUL\n",
    "        if '/' in source_code or 'div' in source_lower:\n",
    "            bytecode += \"04\"  # DIV\n",
    "        if '**' in source_code:\n",
    "            bytecode += \"0a\"  # EXP\n",
    "        \n",
    "        # Loop patterns (common in overflow)\n",
    "        if 'for' in source_lower or 'while' in source_lower:\n",
    "            bytecode += \"5657\"  # JUMP, JUMPI\n",
    "        \n",
    "        # No SafeMath = dangerous\n",
    "        if 'safemath' not in source_lower:\n",
    "            bytecode += \"0102030a\"  # ADD, MUL, SUB, EXP\n",
    "        \n",
    "        # Balance operations\n",
    "        if 'balance' in source_lower:\n",
    "            bytecode += \"31\"  # BALANCE\n",
    "            bytecode += \"0103\"  # ADD, SUB\n",
    "    \n",
    "    # =============== RE-ENTRANCY PATTERNS ===============\n",
    "    if vuln_type == 'Re-entrancy' or 'reentrancy' in vuln_type.lower():\n",
    "        # External call patterns\n",
    "        if '.call' in source_lower:\n",
    "            bytecode += \"f1\"  # CALL\n",
    "            bytecode += \"5455\"  # SLOAD, SSTORE (state after call)\n",
    "        if '.call{value' in source_lower or '.call.value' in source_lower:\n",
    "            bytecode += \"34f1\"  # CALLVALUE, CALL\n",
    "            bytecode += \"55\"  # SSTORE after\n",
    "        if '.send(' in source_lower:\n",
    "            bytecode += \"f2\"  # CALLCODE (similar pattern)\n",
    "        if '.transfer(' in source_lower:\n",
    "            bytecode += \"f1\"  # CALL\n",
    "        if 'delegatecall' in source_lower:\n",
    "            bytecode += \"f4\"  # DELEGATECALL\n",
    "            bytecode += \"5455\"\n",
    "        \n",
    "        # Reentrancy guard absence\n",
    "        if 'reentrancyguard' not in source_lower and 'nonreentrant' not in source_lower:\n",
    "            bytecode += \"f15455\"  # CALL, SLOAD, SSTORE pattern\n",
    "        \n",
    "        # Withdraw pattern\n",
    "        if 'withdraw' in source_lower:\n",
    "            bytecode += \"3454f155\"  # CALLVALUE, SLOAD, CALL, SSTORE\n",
    "    \n",
    "    # =============== TIMESTAMP DEPENDENCE PATTERNS ===============\n",
    "    if vuln_type == 'Timestamp Dependence' or 'timestamp' in vuln_type.lower():\n",
    "        # Block timestamp patterns\n",
    "        if 'block.timestamp' in source_lower or 'blocktimestamp' in source_lower:\n",
    "            bytecode += \"42\"  # TIMESTAMP\n",
    "        if 'block.number' in source_lower or 'blocknumber' in source_lower:\n",
    "            bytecode += \"43\"  # NUMBER\n",
    "        if 'blockhash' in source_lower:\n",
    "            bytecode += \"40\"  # BLOCKHASH\n",
    "        \n",
    "        # Time-dependent logic\n",
    "        if 'now' in source_lower:\n",
    "            bytecode += \"42\"  # TIMESTAMP (now is alias)\n",
    "        \n",
    "        # Modulo operations with timestamp (common vulnerability pattern)\n",
    "        if '%' in source_code and 'timestamp' in source_lower:\n",
    "            bytecode += \"4206\"  # TIMESTAMP, MOD\n",
    "    \n",
    "    # =============== LOOP STATEMENTS PATTERNS ===============\n",
    "    if vuln_type == 'Has Loop' or 'loop' in vuln_type.lower():\n",
    "        # Loop patterns\n",
    "        if 'for' in source_lower:\n",
    "            bytecode += \"5657\"  # JUMP, JUMPI (loop control)\n",
    "            bytecode += \"0103\"  # ADD, SUB (increment/decrement)\n",
    "        if 'while' in source_lower:\n",
    "            bytecode += \"5756\"  # JUMPI, JUMP (while loop)\n",
    "        if 'do' in source_lower and 'while' in source_lower:\n",
    "            bytecode += \"565757\"  # JUMP, JUMPI, JUMPI (do-while)\n",
    "        \n",
    "        # Array iteration patterns\n",
    "        if '.length' in source_lower or 'length' in source_lower:\n",
    "            bytecode += \"5354\"  # MLOAD, SLOAD (array access)\n",
    "    \n",
    "    # =============== COMMON PATTERNS ===============\n",
    "    # State variables\n",
    "    if 'mapping' in source_lower or 'storage' in source_lower:\n",
    "        bytecode += \"5455\"  # SLOAD, SSTORE\n",
    "    \n",
    "    # Require/Assert (protection patterns)\n",
    "    if 'require' in source_lower:\n",
    "        bytecode += \"57\"  # JUMPI\n",
    "        bytecode += \"15\"  # ISZERO\n",
    "    \n",
    "    # Payable functions\n",
    "    if 'payable' in source_lower or 'msg.value' in source_lower:\n",
    "        bytecode += \"34\"  # CALLVALUE\n",
    "    \n",
    "    # Control flow\n",
    "    bytecode += \"565b\"  # JUMP, JUMPDEST\n",
    "    \n",
    "    # Add hash for uniqueness\n",
    "    hash_hex = hashlib.sha256(source_code.encode()).hexdigest()[:32]\n",
    "    bytecode += hash_hex\n",
    "    bytecode += \"f3\"  # RETURN\n",
    "    \n",
    "    return bytecode\n",
    "\n",
    "def load_esc_dataset():\n",
    "    \"\"\"\n",
    "    Load ESC Dataset: 307,396 functions from 40,932 Ethereum smart contracts\n",
    "    - 5,013 functions with call.value (Re-entrancy vulnerability)\n",
    "    - 4,833 functions with block.timestamp (Timestamp dependence vulnerability)\n",
    "    \n",
    "    C·∫¢I THI·ªÜN: T·∫°o dataset ƒëa d·∫°ng h∆°n ƒë·ªÉ tr√°nh perfect separation:\n",
    "    - Th√™m samples c√≥ c·∫£ CALL v√† TIMESTAMP\n",
    "    - Th√™m samples kh√¥ng c√≥ c·∫£ hai\n",
    "    - TƒÉng ƒë·ªô ph·ª©c t·∫°p c·ªßa patterns\n",
    "    \"\"\"\n",
    "    contracts = []\n",
    "    esc_data_path = os.path.join(DATA_DIR, \"esc_dataset\")\n",
    "    \n",
    "    # ‚ö†Ô∏è QUAN TR·ªåNG: Hi·ªán t·∫°i ƒëang s·ª≠ d·ª•ng SYNTHETIC DATA\n",
    "    # ƒê·ªÉ load dataset th·∫≠t ESC, c·∫ßn:\n",
    "    # 1. Download dataset t·ª´ ngu·ªìn ch√≠nh th·ª©c\n",
    "    # 2. Parse file v√† extract bytecode\n",
    "    # 3. Load v√†o ƒë√¢y thay v√¨ generate synthetic\n",
    "    \n",
    "    print(\"   üì• Loading ESC Dataset (Ethereum Smart Contracts)...\")\n",
    "    print(\"   ‚ö†Ô∏è ƒêANG S·ª¨ D·ª§NG SYNTHETIC DATA (kh√¥ng ph·∫£i dataset th·∫≠t)\")\n",
    "    print(\"   üí° Synthetic data ƒë∆∞·ª£c t·∫°o ƒë·ªÉ demo (c·∫£i thi·ªán ƒë·ªÉ tr√°nh overfitting)\")\n",
    "    print(\"   üìå ƒê·ªÉ train tr√™n dataset th·∫≠t, c·∫ßn implement load_esc_dataset_real()\")\n",
    "    \n",
    "    # Simulate ESC dataset structure\n",
    "    num_reentrancy = 5013\n",
    "    num_timestamp = 4833\n",
    "    \n",
    "    # Sample a subset for training\n",
    "    sample_size = min(10000, num_reentrancy + num_timestamp)\n",
    "    \n",
    "    # Ph√¢n b·ªë: 35% pure reentrancy, 35% pure timestamp, 10% c√≥ c·∫£ hai, 20% kh√¥ng c√≥ c·∫£ hai (tƒÉng ambiguous)\n",
    "    num_pure_re = int(sample_size * 0.35)\n",
    "    num_pure_ts = int(sample_size * 0.35)\n",
    "    num_both = int(sample_size * 0.1)\n",
    "    num_neither = int(sample_size * 0.2)  # TƒÉng t·ª´ 10% ‚Üí 20%\n",
    "    \n",
    "    # 1. Generate Pure Re-entrancy samples (c√≥ CALL, kh√¥ng c√≥ TIMESTAMP)\n",
    "    for i in range(num_pure_re):\n",
    "        source_code = f'''\n",
    "        pragma solidity ^0.8.0;\n",
    "        contract ReentrancyVuln_{i} {{\n",
    "            mapping(address => uint256) balances;\n",
    "            function withdraw() public {{\n",
    "                uint256 amount = balances[msg.sender];\n",
    "                (bool success, ) = msg.sender.call{{value: amount}}(\"\");\n",
    "                require(success);\n",
    "                balances[msg.sender] = 0;\n",
    "            }}\n",
    "        }}\n",
    "        '''\n",
    "        bytecode = generate_bytecode_from_source(source_code, 'Re-entrancy')\n",
    "        contracts.append({\n",
    "            'filename': f'reentrancy_{i}.sol',\n",
    "            'source_code': source_code,\n",
    "            'bytecode': bytecode,\n",
    "            'vuln_type': 'Re-entrancy',\n",
    "            'label': VULN_LABELS['Re-entrancy'],\n",
    "            'has_callvalue': True,\n",
    "            'has_timestamp': False\n",
    "        })\n",
    "    \n",
    "    # 2. Generate Pure Timestamp Dependence samples (c√≥ TIMESTAMP, kh√¥ng c√≥ CALL)\n",
    "    for i in range(num_pure_ts):\n",
    "        source_code = f'''\n",
    "        pragma solidity ^0.8.0;\n",
    "        contract TimestampVuln_{i} {{\n",
    "            function lottery() public {{\n",
    "                require(block.timestamp % 7 == 0);\n",
    "                // Vulnerable: depends on block.timestamp\n",
    "            }}\n",
    "        }}\n",
    "        '''\n",
    "        bytecode = generate_bytecode_from_source(source_code, 'Timestamp Dependence')\n",
    "        contracts.append({\n",
    "            'filename': f'timestamp_{i}.sol',\n",
    "            'source_code': source_code,\n",
    "            'bytecode': bytecode,\n",
    "            'vuln_type': 'Timestamp Dependence',\n",
    "            'label': VULN_LABELS['Timestamp Dependence'],\n",
    "            'has_callvalue': False,\n",
    "            'has_timestamp': True\n",
    "        })\n",
    "    \n",
    "    # 3. Generate samples c√≥ C·∫¢ HAI patterns (Re-entrancy nh∆∞ng c≈©ng c√≥ timestamp check)\n",
    "    # Label l√† Re-entrancy v√¨ ƒë√¢y l√† vulnerability ch√≠nh\n",
    "    for i in range(num_both):\n",
    "        source_code = f'''\n",
    "        pragma solidity ^0.8.0;\n",
    "        contract ComplexVuln_{i} {{\n",
    "            mapping(address => uint256) balances;\n",
    "            function withdraw() public {{\n",
    "                require(block.timestamp > 1000);  // C√≥ timestamp check\n",
    "                uint256 amount = balances[msg.sender];\n",
    "                (bool success, ) = msg.sender.call{{value: amount}}(\"\");  // C√≥ call.value\n",
    "                require(success);\n",
    "                balances[msg.sender] = 0;\n",
    "            }}\n",
    "        }}\n",
    "        '''\n",
    "        bytecode = generate_bytecode_from_source(source_code, 'Re-entrancy')\n",
    "        # Th√™m timestamp pattern v√†o bytecode\n",
    "        if '42' not in bytecode.lower():\n",
    "            bytecode = bytecode.replace('f3', '42f3')  # Add TIMESTAMP before RETURN\n",
    "        contracts.append({\n",
    "            'filename': f'complex_re_{i}.sol',\n",
    "            'source_code': source_code,\n",
    "            'bytecode': bytecode,\n",
    "            'vuln_type': 'Re-entrancy',\n",
    "            'label': VULN_LABELS['Re-entrancy'],\n",
    "            'has_callvalue': True,\n",
    "            'has_timestamp': True\n",
    "        })\n",
    "    \n",
    "    # 4. Generate samples KH√îNG C√ì C·∫¢ HAI patterns (harder to classify)\n",
    "    # Ph√¢n b·ªë 50-50 gi·ªØa Re-entrancy v√† Timestamp ƒë·ªÉ t·∫°o confusion\n",
    "    for i in range(num_neither):\n",
    "        if i % 2 == 0:\n",
    "            # Label l√† Re-entrancy nh∆∞ng kh√¥ng c√≥ call.value r√µ r√†ng\n",
    "            source_code = f'''\n",
    "            pragma solidity ^0.8.0;\n",
    "            contract AmbiguousRe_{i} {{\n",
    "                mapping(address => uint256) balances;\n",
    "                function transfer(address to, uint256 amount) public {{\n",
    "                    require(balances[msg.sender] >= amount);\n",
    "                    balances[msg.sender] -= amount;\n",
    "                    balances[to] += amount;\n",
    "                    // No explicit call.value, but has state changes\n",
    "                }}\n",
    "            }}\n",
    "            '''\n",
    "            vuln_type = 'Re-entrancy'\n",
    "            label = VULN_LABELS['Re-entrancy']\n",
    "        else:\n",
    "            # Label l√† Timestamp nh∆∞ng kh√¥ng c√≥ block.timestamp r√µ r√†ng\n",
    "            source_code = f'''\n",
    "            pragma solidity ^0.8.0;\n",
    "            contract AmbiguousTs_{i} {{\n",
    "                function checkCondition() public view returns (bool) {{\n",
    "                    // No explicit block.timestamp, but time-dependent logic\n",
    "                    return true;\n",
    "                }}\n",
    "            }}\n",
    "            '''\n",
    "            vuln_type = 'Timestamp Dependence'\n",
    "            label = VULN_LABELS['Timestamp Dependence']\n",
    "        \n",
    "        bytecode = generate_bytecode_from_source(source_code, vuln_type)\n",
    "        contracts.append({\n",
    "            'filename': f'ambiguous_{i}.sol',\n",
    "            'source_code': source_code,\n",
    "            'bytecode': bytecode,\n",
    "            'vuln_type': vuln_type,\n",
    "            'label': label,\n",
    "            'has_callvalue': False,\n",
    "            'has_timestamp': False\n",
    "        })\n",
    "    \n",
    "    # Shuffle ƒë·ªÉ tr√°nh ordering bias\n",
    "    random.shuffle(contracts)\n",
    "    \n",
    "    print(f\"   ‚úÖ Generated {len(contracts)} ESC samples (SYNTHETIC)\")\n",
    "    print(f\"      - Pure Re-entrancy: {num_pure_re}\")\n",
    "    print(f\"      - Pure Timestamp: {num_pure_ts}\")\n",
    "    print(f\"      - Both patterns: {num_both}\")\n",
    "    print(f\"      - Neither pattern: {num_neither} (increased from 10% to 20%)\")\n",
    "    print(f\"\\n   ‚ö†Ô∏è L∆ØU √ù: ƒê√¢y l√† SYNTHETIC DATA, kh√¥ng ph·∫£i dataset th·∫≠t ESC\")\n",
    "    print(f\"   üìå Dataset th·∫≠t ESC c·∫ßn ƒë∆∞·ª£c download v√† parse t·ª´ ngu·ªìn ch√≠nh th·ª©c\")\n",
    "    return contracts\n",
    "\n",
    "def load_vsc_dataset():\n",
    "    \"\"\"\n",
    "    Load VSC Dataset: 13,761 functions from 4,170 VNT Chain smart contracts\n",
    "    - 2,925 functions with loop statements\n",
    "    \"\"\"\n",
    "    contracts = []\n",
    "    vsc_data_path = os.path.join(DATA_DIR, \"vsc_dataset\")\n",
    "    \n",
    "    print(\"   üì• Loading VSC Dataset (VNT Chain Smart Contracts)...\")\n",
    "    print(\"   üí° ƒêang s·ª≠ d·ª•ng synthetic data cho demo\")\n",
    "    \n",
    "    num_with_loop = 2925\n",
    "    num_without_loop = 13761 - num_with_loop\n",
    "    \n",
    "    sample_size = min(5000, num_with_loop + num_without_loop)\n",
    "    \n",
    "    # Generate samples with loops\n",
    "    for i in range(min(sample_size // 2, num_with_loop)):\n",
    "        source_code = f'''\n",
    "        pragma solidity ^0.8.0;\n",
    "        contract LoopVuln_{i} {{\n",
    "            uint256[] public items;\n",
    "            function processItems() public {{\n",
    "                for(uint256 i = 0; i < items.length; i++) {{\n",
    "                    // Loop statement\n",
    "                    items[i] = items[i] * 2;\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        '''\n",
    "        bytecode = generate_bytecode_from_source(source_code, 'Has Loop')\n",
    "        contracts.append({\n",
    "            'filename': f'loop_{i}.sol',\n",
    "            'source_code': source_code,\n",
    "            'bytecode': bytecode,\n",
    "            'vuln_type': 'Has Loop',\n",
    "            'label': VULN_LABELS['Has Loop'],\n",
    "            'has_loop': True\n",
    "        })\n",
    "    \n",
    "    # Generate samples without loops\n",
    "    for i in range(min(sample_size // 2, num_without_loop)):\n",
    "        source_code = f'''\n",
    "        pragma solidity ^0.8.0;\n",
    "        contract NoLoop_{i} {{\n",
    "            uint256 public value;\n",
    "            function setValue(uint256 v) public {{\n",
    "                value = v;\n",
    "            }}\n",
    "        }}\n",
    "        '''\n",
    "        bytecode = generate_bytecode_from_source(source_code, 'No Loop')\n",
    "        contracts.append({\n",
    "            'filename': f'noloop_{i}.sol',\n",
    "            'source_code': source_code,\n",
    "            'bytecode': bytecode,\n",
    "            'vuln_type': 'No Loop',\n",
    "            'label': VULN_LABELS['No Loop'],\n",
    "            'has_loop': False\n",
    "        })\n",
    "    \n",
    "    print(f\"   ‚úÖ Generated {len(contracts)} VSC samples\")\n",
    "    return contracts\n",
    "\n",
    "# Load dataset based on selection\n",
    "if DATASET_NAME == 'ESC':\n",
    "    all_contracts = load_esc_dataset()\n",
    "elif DATASET_NAME == 'VSC':\n",
    "    all_contracts = load_vsc_dataset()\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset: {DATASET_NAME}\")\n",
    "\n",
    "print(f\"\\n   ‚úÖ Loaded {len(all_contracts)} contracts from {DATASET_NAME} dataset\")\n",
    "\n",
    "# Distribution\n",
    "vuln_counts = Counter([c['vuln_type'] for c in all_contracts])\n",
    "print(\"\\n   üìä Distribution:\")\n",
    "for vuln, count in vuln_counts.items():\n",
    "    pct = (count / len(all_contracts)) * 100\n",
    "    print(f\"      {vuln}: {count} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4e681",
   "metadata": {},
   "source": [
    "## 5. Convert Contracts to HiFi-CFG Graphs\n",
    "\n",
    "Build High-Fidelity CFGs from bytecode and convert to PyG Data objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895af66",
   "metadata": {},
   "source": [
    "## 5.1. Dataset Analysis - Th√¥ng tin Dataset v√† Ph√¢n t√≠ch C·ªôt Th·ªùi gian\n",
    "\n",
    "Ph√¢n t√≠ch dataset ƒë·ªÉ:\n",
    "- Xem th√¥ng tin t·ªïng quan v·ªÅ dataset\n",
    "- Ki·ªÉm tra c·ªôt th·ªùi gian (n·∫øu c√≥)\n",
    "- Ph√¢n t√≠ch quan h·ªá tuy·∫øn t√≠nh gi·ªØa c·ªôt th·ªùi gian v√† nh√£n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd632477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä PH√ÇN T√çCH DATASET - Th√¥ng tin v√† C·ªôt Th·ªùi gian\n",
      "================================================================================\n",
      "\n",
      "1. TH√îNG TIN T·ªîNG QUAN DATASET:\n",
      "--------------------------------------------------------------------------------\n",
      "   T·ªïng s·ªë contracts: 5000\n",
      "   S·ªë c·ªôt: 6\n",
      "\n",
      "   C√°c c·ªôt trong dataset:\n",
      "      - filename\n",
      "      - source_code\n",
      "      - bytecode\n",
      "      - vuln_type\n",
      "      - label\n",
      "      - has_loop\n",
      "\n",
      "2. PH√ÇN B·ªê THEO VULNERABILITY TYPE:\n",
      "--------------------------------------------------------------------------------\n",
      "   Has Loop: 2500 (50.00%)\n",
      "   No Loop: 2500 (50.00%)\n",
      "\n",
      "3. PH√ÇN T√çCH C·ªòT TH·ªúI GIAN (n·∫øu c√≥):\n",
      "--------------------------------------------------------------------------------\n",
      "   ‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt th·ªùi gian trong dataset\n",
      "   üí° Dataset hi·ªán t·∫°i kh√¥ng c√≥ c·ªôt th·ªùi gian, nh∆∞ng c√≥ th·ªÉ th√™m v√†o sau\n",
      "\n",
      "4. PH√ÇN T√çCH TH√äM:\n",
      "--------------------------------------------------------------------------------\n",
      "   - ƒê·ªô d√†i source code (k√Ω t·ª±):\n",
      "      Min: 204, Max: 340, Mean: 273.06\n",
      "\n",
      "   - ƒê·ªô d√†i bytecode (hex):\n",
      "      Min: 48, Max: 60, Mean: 54.00\n",
      "\n",
      "================================================================================\n",
      "‚ö†Ô∏è C·∫¢NH B√ÅO V·ªÄ OVERFITTING - Ph√¢n t√≠ch Feature Leakage\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Ho√†n th√†nh ph√¢n t√≠ch dataset!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5.1: DATASET ANALYSIS - Th√¥ng tin Dataset v√† Ph√¢n t√≠ch C·ªôt Th·ªùi gian\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä PH√ÇN T√çCH DATASET - Th√¥ng tin v√† C·ªôt Th·ªùi gian\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# T·∫°o DataFrame t·ª´ contracts ƒë·ªÉ ph√¢n t√≠ch\n",
    "df_analysis = pd.DataFrame(all_contracts)\n",
    "\n",
    "print(\"\\n1. TH√îNG TIN T·ªîNG QUAN DATASET:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   T·ªïng s·ªë contracts: {len(df_analysis)}\")\n",
    "print(f\"   S·ªë c·ªôt: {len(df_analysis.columns)}\")\n",
    "print(f\"\\n   C√°c c·ªôt trong dataset:\")\n",
    "for col in df_analysis.columns:\n",
    "    print(f\"      - {col}\")\n",
    "\n",
    "print(\"\\n2. PH√ÇN B·ªê THEO VULNERABILITY TYPE:\")\n",
    "print(\"-\" * 80)\n",
    "vuln_counts = df_analysis['vuln_type'].value_counts()\n",
    "for vuln, count in vuln_counts.items():\n",
    "    pct = (count / len(df_analysis)) * 100\n",
    "    print(f\"   {vuln}: {count} ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\n3. PH√ÇN T√çCH C·ªòT TH·ªúI GIAN (n·∫øu c√≥):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Ki·ªÉm tra xem c√≥ c·ªôt th·ªùi gian kh√¥ng\n",
    "time_columns = [col for col in df_analysis.columns if any(keyword in col.lower() \n",
    "                for keyword in ['time', 'timestamp', 'date', 'created', 'updated'])]\n",
    "\n",
    "if time_columns:\n",
    "    print(f\"   ‚úÖ T√¨m th·∫•y {len(time_columns)} c·ªôt th·ªùi gian: {time_columns}\")\n",
    "    for time_col in time_columns:\n",
    "        print(f\"\\n   Ph√¢n t√≠ch c·ªôt '{time_col}':\")\n",
    "        print(f\"      - Ki·ªÉu d·ªØ li·ªáu: {df_analysis[time_col].dtype}\")\n",
    "        print(f\"      - S·ªë gi√° tr·ªã null: {df_analysis[time_col].isnull().sum()}\")\n",
    "        print(f\"      - S·ªë gi√° tr·ªã unique: {df_analysis[time_col].nunique()}\")\n",
    "        \n",
    "        # Chuy·ªÉn ƒë·ªïi sang numeric n·∫øu c√≥ th·ªÉ\n",
    "        try:\n",
    "            time_numeric = pd.to_numeric(df_analysis[time_col], errors='coerce')\n",
    "            if not time_numeric.isnull().all():\n",
    "                print(f\"      - Min: {time_numeric.min()}\")\n",
    "                print(f\"      - Max: {time_numeric.max()}\")\n",
    "                print(f\"      - Mean: {time_numeric.mean():.2f}\")\n",
    "                \n",
    "                # Ph√¢n t√≠ch quan h·ªá tuy·∫øn t√≠nh v·ªõi nh√£n\n",
    "                labels_numeric = df_analysis['label'].values\n",
    "                valid_mask = ~(time_numeric.isnull() | pd.isna(labels_numeric))\n",
    "                \n",
    "                if valid_mask.sum() > 10:  # C·∫ßn √≠t nh·∫•t 10 ƒëi·ªÉm d·ªØ li·ªáu\n",
    "                    time_valid = time_numeric[valid_mask].values\n",
    "                    labels_valid = labels_numeric[valid_mask]\n",
    "                    \n",
    "                    # Pearson correlation\n",
    "                    pearson_r, pearson_p = pearsonr(time_valid, labels_valid)\n",
    "                    print(f\"\\n      üìà QUAN H·ªÜ TUY·∫æN T√çNH V·ªöI NH√ÉN:\")\n",
    "                    print(f\"         - Pearson Correlation (r): {pearson_r:.4f}\")\n",
    "                    print(f\"         - P-value: {pearson_p:.4f}\")\n",
    "                    \n",
    "                    if pearson_p < 0.05:\n",
    "                        print(f\"         ‚úÖ C√≥ quan h·ªá tuy·∫øn t√≠nh c√≥ √Ω nghƒ©a th·ªëng k√™ (p < 0.05)\")\n",
    "                        if abs(pearson_r) > 0.3:\n",
    "                            strength = \"m·∫°nh\" if abs(pearson_r) > 0.7 else \"trung b√¨nh\"\n",
    "                            direction = \"d∆∞∆°ng\" if pearson_r > 0 else \"√¢m\"\n",
    "                            print(f\"         - Quan h·ªá {strength} theo h∆∞·ªõng {direction}\")\n",
    "                        else:\n",
    "                            print(f\"         - Quan h·ªá y·∫øu (|r| < 0.3)\")\n",
    "                    else:\n",
    "                        print(f\"         ‚ùå Kh√¥ng c√≥ quan h·ªá tuy·∫øn t√≠nh c√≥ √Ω nghƒ©a th·ªëng k√™ (p >= 0.05)\")\n",
    "                    \n",
    "                    # Spearman correlation (cho quan h·ªá kh√¥ng tuy·∫øn t√≠nh)\n",
    "                    spearman_r, spearman_p = spearmanr(time_valid, labels_valid)\n",
    "                    print(f\"\\n         - Spearman Correlation (œÅ): {spearman_r:.4f}\")\n",
    "                    print(f\"         - P-value: {spearman_p:.4f}\")\n",
    "                    \n",
    "                    # V·∫Ω bi·ªÉu ƒë·ªì scatter\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.scatter(time_valid, labels_valid, alpha=0.5, s=50)\n",
    "                    plt.xlabel(f'{time_col}')\n",
    "                    plt.ylabel('Label')\n",
    "                    plt.title(f'Quan h·ªá gi·ªØa {time_col} v√† Label\\nPearson r={pearson_r:.4f}, p={pearson_p:.4f}')\n",
    "                    \n",
    "                    # V·∫Ω ƒë∆∞·ªùng h·ªìi quy tuy·∫øn t√≠nh\n",
    "                    z = np.polyfit(time_valid, labels_valid, 1)\n",
    "                    p = np.poly1d(z)\n",
    "                    plt.plot(time_valid, p(time_valid), \"r--\", alpha=0.8, label=f'Linear fit: y={z[0]:.4f}x+{z[1]:.4f}')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(os.path.join(MODEL_SAVE_DIR, f'time_label_correlation_{time_col}.png'), dpi=300)\n",
    "                    plt.show()\n",
    "                    print(f\"         ‚úì Bi·ªÉu ƒë·ªì ƒë√£ l∆∞u: {MODEL_SAVE_DIR}/time_label_correlation_{time_col}.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ö†Ô∏è Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi sang numeric: {e}\")\n",
    "else:\n",
    "    print(\"   ‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt th·ªùi gian trong dataset\")\n",
    "    print(\"   üí° Dataset hi·ªán t·∫°i kh√¥ng c√≥ c·ªôt th·ªùi gian, nh∆∞ng c√≥ th·ªÉ th√™m v√†o sau\")\n",
    "\n",
    "# Ph√¢n t√≠ch th√™m: Ki·ªÉm tra c√°c ƒë·∫∑c tr∆∞ng kh√°c\n",
    "print(\"\\n4. PH√ÇN T√çCH TH√äM:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   - ƒê·ªô d√†i source code (k√Ω t·ª±):\")\n",
    "source_lengths = df_analysis['source_code'].str.len()\n",
    "print(f\"      Min: {source_lengths.min()}, Max: {source_lengths.max()}, Mean: {source_lengths.mean():.2f}\")\n",
    "\n",
    "print(f\"\\n   - ƒê·ªô d√†i bytecode (hex):\")\n",
    "bytecode_lengths = df_analysis['bytecode'].str.len()\n",
    "print(f\"      Min: {bytecode_lengths.min()}, Max: {bytecode_lengths.max()}, Mean: {bytecode_lengths.mean():.2f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# C·∫¢NH B√ÅO V·ªÄ OVERFITTING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚ö†Ô∏è C·∫¢NH B√ÅO V·ªÄ OVERFITTING - Ph√¢n t√≠ch Feature Leakage\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Ki·ªÉm tra m·ªëi quan h·ªá gi·ªØa has_timestamp v√† label\n",
    "if 'has_timestamp' in df_analysis.columns:\n",
    "    timestamp_label_corr = df_analysis['has_timestamp'].astype(int).corr(df_analysis['label'])\n",
    "    print(f\"\\nüìä M·ªëi quan h·ªá has_timestamp v√† Label:\")\n",
    "    print(f\"   - Correlation: {timestamp_label_corr:.4f}\")\n",
    "    \n",
    "    if abs(timestamp_label_corr) > 0.95:\n",
    "        print(f\"\\n   ‚ö†Ô∏è C·∫¢NH B√ÅO: T∆∞∆°ng quan r·∫•t cao (|r| > 0.95)!\")\n",
    "        print(f\"   - ƒêi·ªÅu n√†y c√≥ th·ªÉ d·∫´n ƒë·∫øn overfitting nghi√™m tr·ªçng\")\n",
    "        print(f\"   - Model c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c pattern ƒë∆°n gi·∫£n: has_timestamp ‚Üí Label\")\n",
    "        print(f\"\\n   üí° KHUY·∫æN NGH·ªä:\")\n",
    "        if REMOVE_TIMESTAMP_FEATURE:\n",
    "            print(f\"   ‚úÖ Feature TIMESTAMP (feature 12) ƒë√£ ƒë∆∞·ª£c lo·∫°i b·ªè trong configuration\")\n",
    "            print(f\"      ‚Üí REMOVE_TIMESTAMP_FEATURE = {REMOVE_TIMESTAMP_FEATURE}\")\n",
    "            print(f\"      ‚Üí Model s·∫Ω kh√¥ng s·ª≠ d·ª•ng feature n√†y ƒë·ªÉ tr√°nh overfitting\")\n",
    "        else:\n",
    "            print(f\"   1. ‚úÖ KH√îNG lo·∫°i b·ªè feature TIMESTAMP trong semantic features (feature 12)\")\n",
    "            print(f\"      ‚Üí ƒê√¢y l√† feature h·ª£p l·ªá ƒë·ªÉ ph√°t hi·ªán timestamp dependence\")\n",
    "        print(f\"   2. ‚ö†Ô∏è C·∫¢I THI·ªÜN DATASET:\")\n",
    "        print(f\"      - Th√™m samples c√≥ TIMESTAMP nh∆∞ng KH√îNG ph·∫£i vulnerability\")\n",
    "        print(f\"      - Th√™m samples KH√îNG c√≥ TIMESTAMP nh∆∞ng v·∫´n l√† vulnerability kh√°c\")\n",
    "        print(f\"      - T·∫°o dataset ƒëa d·∫°ng h∆°n, kh√¥ng c√≥ m·ªëi quan h·ªá 1-1\")\n",
    "        print(f\"   3. üîß TƒÇNG REGULARIZATION:\")\n",
    "        print(f\"      - TƒÉng dropout rate (hi·ªán t·∫°i: {DROPOUT})\")\n",
    "        print(f\"      - TƒÉng weight decay (hi·ªán t·∫°i: {WEIGHT_DECAY})\")\n",
    "        print(f\"      - Th√™m L2 regularization cho features\")\n",
    "        print(f\"   4. üìà MONITOR TRAINING:\")\n",
    "        print(f\"      - Theo d√µi gap gi·ªØa train v√† validation accuracy\")\n",
    "        print(f\"      - N·∫øu validation accuracy th·∫•p h∆°n train nhi·ªÅu ‚Üí overfitting\")\n",
    "        print(f\"      - S·ª≠ d·ª•ng early stopping nghi√™m ng·∫∑t h∆°n\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚úÖ T∆∞∆°ng quan ·ªü m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c (|r| <= 0.95)\")\n",
    "\n",
    "# Ki·ªÉm tra t∆∞∆°ng t·ª± cho has_callvalue\n",
    "if 'has_callvalue' in df_analysis.columns:\n",
    "    callvalue_label_corr = df_analysis['has_callvalue'].astype(int).corr(df_analysis['label'])\n",
    "    print(f\"\\nüìä M·ªëi quan h·ªá has_callvalue v√† Label:\")\n",
    "    print(f\"   - Correlation: {callvalue_label_corr:.4f}\")\n",
    "    \n",
    "    if abs(callvalue_label_corr) > 0.95:\n",
    "        print(f\"   ‚ö†Ô∏è C·∫¢NH B√ÅO: T∆∞∆°ng quan r·∫•t cao v·ªõi has_callvalue!\")\n",
    "\n",
    "print(\"\\n‚úÖ Ho√†n th√†nh ph√¢n t√≠ch dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c8ee1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîÑ CONVERTING CONTRACTS TO HIGH-FIDELITY CFG GRAPHS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Building HiFi-CFGs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:02<00:00, 2076.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ Converted 5000 graphs\n",
      "   üìä Feature dimensions: torch.Size([5, 164])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: CONVERT TO HIFI-CFG GRAPHS\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üîÑ CONVERTING CONTRACTS TO HIGH-FIDELITY CFG GRAPHS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_graphs = []\n",
    "graph_labels = []\n",
    "\n",
    "for contract in tqdm(all_contracts, desc=\"   Building HiFi-CFGs\"):\n",
    "    try:\n",
    "        # Build CFG from bytecode\n",
    "        cfg = cfg_builder.build_cfg(contract['bytecode'])\n",
    "        \n",
    "        # Convert to PyG Data\n",
    "        graph_data = cfg_builder.cfg_to_pyg_data(cfg)\n",
    "        \n",
    "        if graph_data is None:\n",
    "            continue\n",
    "        \n",
    "        # Add label\n",
    "        graph_data.y = torch.tensor([contract['label']], dtype=torch.long)\n",
    "        \n",
    "        all_graphs.append(graph_data)\n",
    "        graph_labels.append(contract['label'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "print(f\"\\n   ‚úÖ Converted {len(all_graphs)} graphs\")\n",
    "print(f\"   üìä Feature dimensions: {all_graphs[0].x.shape if all_graphs else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846834ba",
   "metadata": {},
   "source": [
    "## 6. Data Splitting and Augmentation (80/20 Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e48b9929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä DATA SPLITTING - 80% TRAIN / 20% TEST\n",
      "================================================================================\n",
      "   Train: 3600 graphs\n",
      "   Validation: 400 graphs\n",
      "   Test: 1000 graphs\n",
      "\n",
      "   üìà Augmented train: 3600 ‚Üí 7200 (2x)\n",
      "\n",
      "   üîÄ Injecting label noise (5.0% rate)...\n",
      "   ‚úÖ Label noise injected\n",
      "\n",
      "   ‚öñÔ∏è Class weights:\n",
      "      No Loop: 1.0000\n",
      "      Has Loop: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: DATA SPLITTING AND AUGMENTATION\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä DATA SPLITTING - 80% TRAIN / 20% TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Stratified split\n",
    "labels = np.array(graph_labels)\n",
    "indices = np.arange(len(all_graphs))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, test_size=0.2, stratify=labels, random_state=SEED\n",
    ")\n",
    "\n",
    "# Further split train into train/val (90/10)\n",
    "train_labels = labels[train_idx]\n",
    "train_idx_final, val_idx = train_test_split(\n",
    "    train_idx, test_size=0.1, stratify=train_labels, random_state=SEED\n",
    ")\n",
    "\n",
    "train_graphs = [all_graphs[i] for i in train_idx_final]\n",
    "val_graphs = [all_graphs[i] for i in val_idx]\n",
    "test_graphs = [all_graphs[i] for i in test_idx]\n",
    "\n",
    "print(f\"   Train: {len(train_graphs)} graphs\")\n",
    "print(f\"   Validation: {len(val_graphs)} graphs\")\n",
    "print(f\"   Test: {len(test_graphs)} graphs\")\n",
    "\n",
    "# Data Augmentation v·ªõi noise m·∫°nh h∆°n ƒë·ªÉ ch·ªëng overfitting\n",
    "def augment_graph(graph, noise_level=0.2, dropout_prob=0.2):\n",
    "    \"\"\"Augment graph features with noise and dropout\"\"\"\n",
    "    new_x = graph.x.clone()\n",
    "    # Add Gaussian noise\n",
    "    noise = torch.randn_like(new_x) * noise_level\n",
    "    new_x = new_x + noise\n",
    "    # Feature dropout\n",
    "    mask = torch.rand_like(new_x) > dropout_prob\n",
    "    new_x = new_x * mask.float()\n",
    "    # Clamp to valid range\n",
    "    new_x = torch.clamp(new_x, 0, 1)\n",
    "    return Data(x=new_x, edge_index=graph.edge_index.clone(), y=graph.y.clone())\n",
    "\n",
    "# Augment training data (2x) v·ªõi noise m·∫°nh h∆°n - gi·∫£m augmentation ƒë·ªÉ tr√°nh qu√° nhi·ªÅu noise\n",
    "augmented_train = []\n",
    "for g in train_graphs:\n",
    "    augmented_train.append(g)\n",
    "    # TƒÉng noise level ƒë·ªÉ t·∫°o diversity\n",
    "    augmented_train.append(augment_graph(g, noise_level=0.15, dropout_prob=0.15))\n",
    "\n",
    "print(f\"\\n   üìà Augmented train: {len(train_graphs)} ‚Üí {len(augmented_train)} (2x)\")\n",
    "\n",
    "# Compute class weights\n",
    "train_labels_aug = [g.y.item() for g in augmented_train]\n",
    "base_weights = compute_class_weight('balanced', classes=np.unique(train_labels_aug), y=train_labels_aug)\n",
    "\n",
    "# Apply custom multipliers\n",
    "class_weights = torch.tensor([\n",
    "    base_weights[0] * CLASS_WEIGHT_0,\n",
    "    base_weights[1] * CLASS_WEIGHT_1\n",
    "], dtype=torch.float).to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# LABEL NOISE INJECTION - Th√™m noise v√†o labels ƒë·ªÉ ch·ªëng overfitting\n",
    "# =============================================================================\n",
    "LABEL_NOISE_RATE = 0.05  # 5% labels s·∫Ω b·ªã flip ng·∫´u nhi√™n\n",
    "\n",
    "def inject_label_noise(graphs, noise_rate=LABEL_NOISE_RATE):\n",
    "    \"\"\"Inject random label noise to prevent overfitting\"\"\"\n",
    "    noisy_graphs = []\n",
    "    num_classes = len(TARGET_VULNS)\n",
    "    \n",
    "    for graph in graphs:\n",
    "        # T·∫°o copy m·ªõi\n",
    "        new_graph = Data(\n",
    "            x=graph.x.clone(),\n",
    "            edge_index=graph.edge_index.clone(),\n",
    "            y=graph.y.clone()\n",
    "        )\n",
    "        \n",
    "        # Randomly flip label v·ªõi x√°c su·∫•t noise_rate\n",
    "        if random.random() < noise_rate:\n",
    "            original_label = graph.y.item()\n",
    "            # Flip sang class kh√°c\n",
    "            new_label = 1 - original_label if num_classes == 2 else random.choice(\n",
    "                [i for i in range(num_classes) if i != original_label]\n",
    "            )\n",
    "            new_graph.y = torch.tensor([new_label], dtype=torch.long)\n",
    "        \n",
    "        noisy_graphs.append(new_graph)\n",
    "    \n",
    "    return noisy_graphs\n",
    "\n",
    "# √Åp d·ª•ng label noise cho training data\n",
    "print(f\"\\n   üîÄ Injecting label noise ({LABEL_NOISE_RATE*100:.1f}% rate)...\")\n",
    "augmented_train = inject_label_noise(augmented_train, noise_rate=LABEL_NOISE_RATE)\n",
    "print(f\"   ‚úÖ Label noise injected\")\n",
    "\n",
    "print(f\"\\n   ‚öñÔ∏è Class weights:\")\n",
    "for i, vuln_name in enumerate(TARGET_VULNS):\n",
    "    print(f\"      {vuln_name}: {class_weights[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b850b2",
   "metadata": {},
   "source": [
    "## 7. GraphSAGE Model\n",
    "\n",
    "Implements the GraphSAGE (Graph Sample and Aggregate) architecture:\n",
    "\n",
    "$$\\mathbf{h}_v^k = \\sigma(\\mathbf{W}^k \\cdot \\text{CONCAT}(\\mathbf{h}_v^{k-1}, \\text{AGG}(\\{\\mathbf{h}_u^{k-1}, \\forall u \\in \\mathcal{N}(v)\\})))$$\n",
    "\n",
    "Where:\n",
    "- **Sample**: Randomly sample neighbors for each node\n",
    "- **Aggregate**: Aggregate features from sampled neighbors (mean, max, or LSTM)\n",
    "- **Update**: Update node embeddings using aggregated neighbor features\n",
    "\n",
    "GraphSAGE is inductive and can generalize to unseen nodes/graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e851f1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Creating DataLoaders and Model\n",
      "============================================================\n",
      "Train batches: 113\n",
      "Val batches: 7\n",
      "Test batches: 16\n",
      "\n",
      "Input feature dimension: 164\n",
      "\n",
      "Model Summary:\n",
      "  - Hidden channels: 32\n",
      "  - GraphSAGE layers: 2\n",
      "  - Total parameters: 12,610\n",
      "\n",
      "Optimizer: Adam (lr=0.0003, weight_decay=0.002)\n",
      "Loss: Label Smoothing CrossEntropy (smoothing=0.3)\n",
      "\n",
      "‚ö†Ô∏è ANTI-OVERFITTING MEASURES (AGGRESSIVE):\n",
      "   - Model Capacity: 32 hidden channels (reduced from 64)\n",
      "   - Dropout: 0.6 (increased from 0.3)\n",
      "   - Weight Decay: 0.002 (increased from 1e-4)\n",
      "   - Learning Rate: 0.0003 (reduced from 1e-3)\n",
      "   - Label Smoothing: 0.3 (increased from 0.1)\n",
      "   - Batch Size: 64 (increased for stability)\n",
      "   - Patience: 10 (more aggressive early stopping)\n",
      "   - REMOVE_TIMESTAMP_FEATURE: True\n",
      "   - Dataset: Improved with diverse patterns (both, neither)\n",
      "\n",
      "‚úÖ Model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 7: HiFi-GraphSAGE Model Architecture\n",
    "# =============================================================================\n",
    "from torch.optim import Adam\n",
    "\n",
    "class HiFiGraphSAGE(nn.Module):\n",
    "    \"\"\"\n",
    "    High-Fidelity GraphSAGE for Vulnerability Detection\n",
    "    Uses Graph Sample and Aggregate approach for inductive learning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = HIDDEN_CHANNELS,\n",
    "        output_dim: int = NUM_CLASSES,\n",
    "        num_layers: int = NUM_SAGE_LAYERS,\n",
    "        dropout: float = DROPOUT\n",
    "    ):\n",
    "        super(HiFiGraphSAGE, self).__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # GraphSAGE layers\n",
    "        self.sage_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_dim = hidden_dim if i == 0 else hidden_dim\n",
    "            self.sage_layers.append(\n",
    "                SAGEConv(in_dim, hidden_dim, normalize=True)\n",
    "            )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim),  # 3 pooling types\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Input projection\n",
    "        x = F.relu(self.input_proj(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # GraphSAGE layers\n",
    "        for sage in self.sage_layers:\n",
    "            x = sage(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Global pooling\n",
    "        x_mean = global_mean_pool(x, batch)\n",
    "        x_max = global_max_pool(x, batch)\n",
    "        x_add = global_add_pool(x, batch)\n",
    "        x = torch.cat([x_mean, x_max, x_add], dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Create DataLoaders\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Creating DataLoaders and Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_loader = DataLoader(augmented_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_graphs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Get input dimension\n",
    "input_dim = augmented_train[0].x.shape[1]\n",
    "print(f\"\\nInput feature dimension: {input_dim}\")\n",
    "\n",
    "# Initialize model\n",
    "model = HiFiGraphSAGE(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=HIDDEN_CHANNELS,\n",
    "    output_dim=NUM_CLASSES,\n",
    "    num_layers=NUM_SAGE_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"  - Hidden channels: {HIDDEN_CHANNELS}\")\n",
    "print(f\"  - GraphSAGE layers: {NUM_SAGE_LAYERS}\")\n",
    "print(f\"  - Total parameters: {total_params:,}\")\n",
    "\n",
    "# Initialize optimizer - Adam with lr=1e-3, weight_decay=1e-4\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Loss function - Label Smoothing CrossEntropy ƒë·ªÉ ch·ªëng overfitting\n",
    "LABEL_SMOOTHING = 0.3  # Increased to 30% label smoothing (was 0.2)\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, weight=None):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        log_prob = F.log_softmax(pred, dim=1)\n",
    "        nll_loss = -log_prob.gather(dim=1, index=target.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        if self.weight is not None:\n",
    "            nll_loss = nll_loss * self.weight[target]\n",
    "        \n",
    "        smooth_loss = -log_prob.mean(dim=1)\n",
    "        if self.weight is not None:\n",
    "            smooth_loss = smooth_loss * self.weight.mean()\n",
    "        \n",
    "        loss = (1.0 - self.smoothing) * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n",
    "\n",
    "# S·ª≠ d·ª•ng label smoothing loss\n",
    "criterion = LabelSmoothingCrossEntropy(smoothing=LABEL_SMOOTHING, weight=class_weights)\n",
    "\n",
    "print(f\"\\nOptimizer: Adam (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\")\n",
    "print(f\"Loss: Label Smoothing CrossEntropy (smoothing={LABEL_SMOOTHING})\")\n",
    "print(f\"\\n‚ö†Ô∏è ANTI-OVERFITTING MEASURES (AGGRESSIVE):\")\n",
    "print(f\"   - Model Capacity: {HIDDEN_CHANNELS} hidden channels (reduced from 64)\")\n",
    "print(f\"   - Dropout: {DROPOUT} (increased from 0.3)\")\n",
    "print(f\"   - Weight Decay: {WEIGHT_DECAY} (increased from 1e-4)\")\n",
    "print(f\"   - Learning Rate: {LEARNING_RATE} (reduced from 1e-3)\")\n",
    "print(f\"   - Label Smoothing: {LABEL_SMOOTHING} (increased from 0.1)\")\n",
    "print(f\"   - Batch Size: {BATCH_SIZE} (increased for stability)\")\n",
    "print(f\"   - Patience: {PATIENCE} (more aggressive early stopping)\")\n",
    "print(f\"   - REMOVE_TIMESTAMP_FEATURE: {REMOVE_TIMESTAMP_FEATURE}\")\n",
    "print(f\"   - Dataset: Improved with diverse patterns (both, neither)\")\n",
    "print(\"\\n‚úÖ Model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4d605",
   "metadata": {},
   "source": [
    "## 8. Training Loop with Early Stopping\n",
    "\n",
    "Training procedure with:\n",
    "- Batch processing\n",
    "- Validation monitoring\n",
    "- Early stopping based on validation loss\n",
    "- Learning rate scheduling\n",
    "- Best model checkpoint saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85e53c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting Training\n",
      "============================================================\n",
      "\n",
      "Training for 100 epochs (patience=10)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 | Train Loss: 0.6963 | Val Loss: 0.6902 | Val Acc: 0.5000 | Val F1: 0.3333 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2/100 | Train Loss: 0.6862 | Val Loss: 0.6740 | Val Acc: 0.6975 | Val F1: 0.6670 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3/100 | Train Loss: 0.6650 | Val Loss: 0.5805 | Val Acc: 0.9225 | Val F1: 0.9220 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4/100 | Train Loss: 0.6053 | Val Loss: 0.4838 | Val Acc: 0.9850 | Val F1: 0.9850 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8/100 | Train Loss: 0.5290 | Val Loss: 0.4502 | Val Acc: 0.9875 | Val F1: 0.9875 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10/100 | Train Loss: 0.5184 | Val Loss: 0.4496 | Val Acc: 0.9875 | Val F1: 0.9875 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  13/100 | Train Loss: 0.5161 | Val Loss: 0.4439 | Val Acc: 0.9900 | Val F1: 0.9900 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  15/100 | Train Loss: 0.5100 | Val Loss: 0.4451 | Val Acc: 0.9925 | Val F1: 0.9925 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20/100 | Train Loss: 0.5074 | Val Loss: 0.4430 | Val Acc: 0.9950 | Val F1: 0.9950 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21/100 | Train Loss: 0.5058 | Val Loss: 0.4433 | Val Acc: 0.9975 | Val F1: 0.9975 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24/100 | Train Loss: 0.5039 | Val Loss: 0.4414 | Val Acc: 1.0000 | Val F1: 1.0000 ‚úì BEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30/100 | Train Loss: 0.4997 | Val Loss: 0.4443 | Val Acc: 0.9950 | Val F1: 0.9950 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö† Early stopping at epoch 34\n",
      "\n",
      "============================================================\n",
      "Training completed! Best Val F1: 1.0000\n",
      "============================================================\n",
      "‚úì Loaded best model\n",
      "‚úì Model saved to ./saved_models/hifi_graphsage_vsc.pth\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 8: Training Loop (Simplified)\n",
    "# =============================================================================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(batch)\n",
    "        loss = criterion(logits, batch.y.squeeze())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # TƒÉng gradient clipping ƒë·ªÉ ·ªïn ƒë·ªãnh training\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)  # Reduced from 1.0\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == batch.y.squeeze()).sum().item()\n",
    "        total += batch.num_graphs\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            logits = model(batch)\n",
    "            loss = criterion(logits, batch.y.squeeze())\n",
    "            \n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch.y.squeeze().cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = (all_preds == all_labels).mean()\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return total_loss / len(all_labels), accuracy, f1, all_preds, all_labels\n",
    "\n",
    "\n",
    "# Training\n",
    "print(\"=\" * 60)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_val_f1 = 0\n",
    "best_model_state = None\n",
    "patience_counter = 0\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_f1': []}\n",
    "\n",
    "print(f\"\\nTraining for {EPOCHS} epochs (patience={PATIENCE})\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1, val_preds, val_labels = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Check for best model\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        improved = \"‚úì BEST\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        improved = \"\"\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 10 == 0 or epoch == 1 or improved:\n",
    "        print(f\"Epoch {epoch:3d}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f} {improved}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\n‚ö† Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Training completed! Best Val F1: {best_val_f1:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"‚úì Loaded best model\")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "model_path = os.path.join(MODEL_SAVE_DIR, f'hifi_graphsage_{DATASET_NAME.lower()}.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': best_model_state,\n",
    "    'input_dim': input_dim,\n",
    "    'hidden_dim': HIDDEN_CHANNELS,\n",
    "    'num_classes': NUM_CLASSES\n",
    "}, model_path)\n",
    "print(f\"‚úì Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1b258",
   "metadata": {},
   "source": [
    "## 9. Threshold Optimization\n",
    "\n",
    "Optimize decision thresholds for each vulnerability class to maximize F1 score:\n",
    "- Search thresholds in range [0.1, 0.9]\n",
    "- Per-class optimization for Overflow-Underflow and Re-entrancy\n",
    "- Balance between precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb53a64",
   "metadata": {},
   "source": [
    "## 9.1. Ph√¢n t√≠ch Overfitting - Feature Importance v√† Model Behavior\n",
    "\n",
    "Ph√¢n t√≠ch xem model ƒëang h·ªçc ƒë∆∞·ª£c g√¨ v√† t·∫°i sao ƒë·∫°t 100% accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3870033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç PH√ÇN T√çCH OVERFITTING - T·∫°i sao model ƒë·∫°t 100% accuracy?\n",
      "================================================================================\n",
      "\n",
      "1. PH√ÇN T√çCH S·ª∞ KH√ÅC BI·ªÜT TRONG BYTECODE:\n",
      "--------------------------------------------------------------------------------\n",
      "   Re-entrancy contracts patterns:\n",
      "\n",
      "   Timestamp Dependence contracts patterns:\n",
      "\n",
      "2. PH√ÇN T√çCH FEATURE STATISTICS:\n",
      "--------------------------------------------------------------------------------\n",
      "   Top 20 features c√≥ s·ª± kh√°c bi·ªát l·ªõn nh·∫•t gi·ªØa 2 classes:\n",
      "      Feature 154: diff=0.1537 (Re=0.0100, TS=0.1637)\n",
      "      Feature 59: diff=0.1537 (Re=0.0100, TS=0.1637)\n",
      "      Feature 152: diff=0.1526 (Re=0.0111, TS=0.1637)\n",
      "      Feature 155: diff=0.0935 (Re=0.0903, TS=0.1837)\n",
      "      Feature 141: diff=0.0795 (Re=0.3506, TS=0.2711)\n",
      "      Feature 63: diff=0.0572 (Re=0.1255, TS=0.0684)\n",
      "      Feature 55: diff=0.0327 (Re=0.0000, TS=0.0327)\n",
      "      Feature 56: diff=0.0309 (Re=0.0019, TS=0.0327)\n",
      "      Feature 1: diff=0.0290 (Re=0.0037, TS=0.0327)\n",
      "      Feature 112: diff=0.0283 (Re=0.0512, TS=0.0229)\n",
      "      Feature 156: diff=0.0257 (Re=0.0090, TS=0.0347)\n",
      "      Feature 96: diff=0.0255 (Re=0.0019, TS=0.0273)\n",
      "      Feature 3: diff=0.0253 (Re=0.0074, TS=0.0327)\n",
      "      Feature 136: diff=0.0235 (Re=0.0371, TS=0.0136)\n",
      "      Feature 58: diff=0.0223 (Re=0.0580, TS=0.0803)\n",
      "      Feature 24: diff=0.0222 (Re=0.0222, TS=0.0000)\n",
      "      Feature 54: diff=0.0163 (Re=0.0573, TS=0.0409)\n",
      "      Feature 160: diff=0.0154 (Re=0.1219, TS=0.1065)\n",
      "      Feature 64: diff=0.0154 (Re=0.1219, TS=0.1065)\n",
      "      Feature 153: diff=0.0143 (Re=0.0143, TS=0.0000)\n",
      "\n",
      "3. PH√ÇN T√çCH GRAPH STRUCTURE:\n",
      "--------------------------------------------------------------------------------\n",
      "   Re-entrancy graphs:\n",
      "      Node count - Mean: 6.30, Std: 2.72, Range: [2, 10]\n",
      "   Timestamp Dependence graphs:\n",
      "      Node count - Mean: 7.40, Std: 3.14, Range: [4, 12]\n",
      "\n",
      "   Re-entrancy graphs:\n",
      "      Edge count - Mean: 1.00, Std: 0.00\n",
      "   Timestamp Dependence graphs:\n",
      "      Edge count - Mean: 1.00, Std: 0.00\n",
      "\n",
      "4. PH√ÇN T√çCH MODEL CONFIDENCE:\n",
      "--------------------------------------------------------------------------------\n",
      "   Confidence statistics:\n",
      "      Mean: 0.7720\n",
      "      Std: 0.0243\n",
      "      Min: 0.5082\n",
      "      Max: 0.8038\n",
      "\n",
      "================================================================================\n",
      "üí° ƒê·ªÄ XU·∫§T GI·∫¢I PH√ÅP CH·ªêNG OVERFITTING:\n",
      "================================================================================\n",
      "\n",
      "1. ‚úÖ ƒê√É TH·ª∞C HI·ªÜN:\n",
      "   - Lo·∫°i b·ªè feature TIMESTAMP (REMOVE_TIMESTAMP_FEATURE = True)\n",
      "   - TƒÉng dropout t·ª´ 0.3 ‚Üí 0.5\n",
      "   - TƒÉng weight decay t·ª´ 1e-4 ‚Üí 1e-3\n",
      "   - Gi·∫£m learning rate t·ª´ 1e-3 ‚Üí 5e-4\n",
      "   - TƒÉng noise trong data augmentation\n",
      "\n",
      "2. üîß C·∫¶N TH·ª∞C HI·ªÜN TH√äM:\n",
      "   - Th√™m label smoothing trong loss function\n",
      "   - S·ª≠ d·ª•ng Mixup ho·∫∑c CutMix cho graph augmentation\n",
      "   - Th√™m feature dropout ri√™ng cho semantic features\n",
      "   - Gi·∫£m model capacity (hidden channels ho·∫∑c layers)\n",
      "   - Th√™m early stopping nghi√™m ng·∫∑t h∆°n\n",
      "   - S·ª≠ d·ª•ng validation set l·ªõn h∆°n\n",
      "\n",
      "3. üìä C·∫¢I THI·ªÜN DATASET:\n",
      "   - T·∫°o dataset ƒëa d·∫°ng h∆°n, kh√¥ng c√≥ pattern r√µ r√†ng\n",
      "   - Th√™m samples c√≥ c·∫£ CALL v√† TIMESTAMP\n",
      "   - Th√™m samples kh√¥ng c√≥ c·∫£ CALL v√† TIMESTAMP\n",
      "   - TƒÉng ƒë·ªô ph·ª©c t·∫°p c·ªßa synthetic bytecode\n",
      "\n",
      "\n",
      "‚úÖ Ho√†n th√†nh ph√¢n t√≠ch overfitting!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9.1: PH√ÇN T√çCH OVERFITTING - Feature Importance v√† Model Behavior\n",
    "# =============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üîç PH√ÇN T√çCH OVERFITTING - T·∫°i sao model ƒë·∫°t 100% accuracy?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Ki·ªÉm tra s·ª± kh√°c bi·ªát gi·ªØa 2 classes trong bytecode\n",
    "print(\"\\n1. PH√ÇN T√çCH S·ª∞ KH√ÅC BI·ªÜT TRONG BYTECODE:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "reentrancy_contracts = [c for c in all_contracts if c['vuln_type'] == 'Re-entrancy']\n",
    "timestamp_contracts = [c for c in all_contracts if c['vuln_type'] == 'Timestamp Dependence']\n",
    "\n",
    "# Ph√¢n t√≠ch bytecode patterns\n",
    "reentrancy_bytecodes = [c['bytecode'] for c in reentrancy_contracts[:100]]  # Sample\n",
    "timestamp_bytecodes = [c['bytecode'] for c in timestamp_contracts[:100]]  # Sample\n",
    "\n",
    "# T√¨m c√°c opcode patterns ƒë·∫∑c tr∆∞ng\n",
    "def extract_opcode_patterns(bytecode_list):\n",
    "    \"\"\"Extract common opcode patterns\"\"\"\n",
    "    patterns = Counter()\n",
    "    for bc in bytecode_list:\n",
    "        # Look for specific hex patterns\n",
    "        if 'f1' in bc.lower():  # CALL\n",
    "            patterns['CALL'] += 1\n",
    "        if '34' in bc.lower():  # CALLVALUE\n",
    "            patterns['CALLVALUE'] += 1\n",
    "        if '42' in bc.lower():  # TIMESTAMP\n",
    "            patterns['TIMESTAMP'] += 1\n",
    "        if '43' in bc.lower():  # NUMBER\n",
    "            patterns['NUMBER'] += 1\n",
    "        if '54' in bc.lower():  # SLOAD\n",
    "            patterns['SLOAD'] += 1\n",
    "        if '55' in bc.lower():  # SSTORE\n",
    "            patterns['SSTORE'] += 1\n",
    "    return patterns\n",
    "\n",
    "re_patterns = extract_opcode_patterns(reentrancy_bytecodes)\n",
    "ts_patterns = extract_opcode_patterns(timestamp_bytecodes)\n",
    "\n",
    "print(\"   Re-entrancy contracts patterns:\")\n",
    "for pattern, count in re_patterns.most_common(10):\n",
    "    pct = (count / len(reentrancy_bytecodes)) * 100\n",
    "    print(f\"      {pattern}: {count}/{len(reentrancy_bytecodes)} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n   Timestamp Dependence contracts patterns:\")\n",
    "for pattern, count in ts_patterns.most_common(10):\n",
    "    pct = (count / len(timestamp_bytecodes)) * 100\n",
    "    print(f\"      {pattern}: {count}/{len(timestamp_bytecodes)} ({pct:.1f}%)\")\n",
    "\n",
    "# 2. Ph√¢n t√≠ch feature statistics\n",
    "print(\"\\n2. PH√ÇN T√çCH FEATURE STATISTICS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# L·∫•y m·ªôt sample graph t·ª´ m·ªói class\n",
    "re_graphs = [g for g, l in zip(all_graphs, graph_labels) if l == 0][:10]\n",
    "ts_graphs = [g for g, l in zip(all_graphs, graph_labels) if l == 1][:10]\n",
    "\n",
    "if re_graphs and ts_graphs:\n",
    "    # T√≠nh mean features cho m·ªói class\n",
    "    re_features = torch.stack([g.x.mean(dim=0) for g in re_graphs]).mean(dim=0)\n",
    "    ts_features = torch.stack([g.x.mean(dim=0) for g in ts_graphs]).mean(dim=0)\n",
    "    \n",
    "    # T√≠nh s·ª± kh√°c bi·ªát\n",
    "    feature_diff = torch.abs(re_features - ts_features)\n",
    "    top_diff_indices = torch.argsort(feature_diff, descending=True)[:20]\n",
    "    \n",
    "    print(f\"   Top 20 features c√≥ s·ª± kh√°c bi·ªát l·ªõn nh·∫•t gi·ªØa 2 classes:\")\n",
    "    for idx in top_diff_indices:\n",
    "        diff_val = feature_diff[idx].item()\n",
    "        re_val = re_features[idx].item()\n",
    "        ts_val = ts_features[idx].item()\n",
    "        print(f\"      Feature {idx.item()}: diff={diff_val:.4f} (Re={re_val:.4f}, TS={ts_val:.4f})\")\n",
    "    \n",
    "    # Ki·ªÉm tra xem c√≥ feature n√†o c√≥ th·ªÉ ph√¢n bi·ªát ho√†n to√†n kh√¥ng\n",
    "    perfect_separators = []\n",
    "    for idx in range(len(feature_diff)):\n",
    "        re_vals = [g.x[:, idx].mean().item() for g in re_graphs]\n",
    "        ts_vals = [g.x[:, idx].mean().item() for g in ts_graphs]\n",
    "        if len(set(re_vals)) == 1 and len(set(ts_vals)) == 1 and re_vals[0] != ts_vals[0]:\n",
    "            perfect_separators.append(idx)\n",
    "    \n",
    "    if perfect_separators:\n",
    "        print(f\"\\n   ‚ö†Ô∏è C·∫¢NH B√ÅO: T√¨m th·∫•y {len(perfect_separators)} features c√≥ th·ªÉ ph√¢n bi·ªát ho√†n to√†n 2 classes!\")\n",
    "        print(f\"      Features: {perfect_separators[:10]}\")\n",
    "        print(f\"      ‚Üí ƒê√¢y c√≥ th·ªÉ l√† nguy√™n nh√¢n g√¢y overfitting!\")\n",
    "\n",
    "# 3. Ph√¢n t√≠ch graph structure\n",
    "print(\"\\n3. PH√ÇN T√çCH GRAPH STRUCTURE:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "re_sizes = [g.x.shape[0] for g in re_graphs]\n",
    "ts_sizes = [g.x.shape[0] for g in ts_graphs]\n",
    "\n",
    "print(f\"   Re-entrancy graphs:\")\n",
    "print(f\"      Node count - Mean: {np.mean(re_sizes):.2f}, Std: {np.std(re_sizes):.2f}, Range: [{min(re_sizes)}, {max(re_sizes)}]\")\n",
    "print(f\"   Timestamp Dependence graphs:\")\n",
    "print(f\"      Node count - Mean: {np.mean(ts_sizes):.2f}, Std: {np.std(ts_sizes):.2f}, Range: [{min(ts_sizes)}, {max(ts_sizes)}]\")\n",
    "\n",
    "re_edges = [g.edge_index.shape[1] for g in re_graphs]\n",
    "ts_edges = [g.edge_index.shape[1] for g in ts_graphs]\n",
    "\n",
    "print(f\"\\n   Re-entrancy graphs:\")\n",
    "print(f\"      Edge count - Mean: {np.mean(re_edges):.2f}, Std: {np.std(re_edges):.2f}\")\n",
    "print(f\"   Timestamp Dependence graphs:\")\n",
    "print(f\"      Edge count - Mean: {np.mean(ts_edges):.2f}, Std: {np.std(ts_edges):.2f}\")\n",
    "\n",
    "# 4. Ki·ªÉm tra model confidence\n",
    "print(\"\\n4. PH√ÇN T√çCH MODEL CONFIDENCE:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "model.eval()\n",
    "all_confidences = []\n",
    "all_labels_conf = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        confidences = probs.max(dim=1)[0].cpu().numpy()\n",
    "        all_confidences.extend(confidences)\n",
    "        all_labels_conf.extend(batch.y.squeeze().cpu().numpy())\n",
    "\n",
    "all_confidences = np.array(all_confidences)\n",
    "print(f\"   Confidence statistics:\")\n",
    "print(f\"      Mean: {all_confidences.mean():.4f}\")\n",
    "print(f\"      Std: {all_confidences.std():.4f}\")\n",
    "print(f\"      Min: {all_confidences.min():.4f}\")\n",
    "print(f\"      Max: {all_confidences.max():.4f}\")\n",
    "\n",
    "if all_confidences.mean() > 0.99:\n",
    "    print(f\"\\n   ‚ö†Ô∏è C·∫¢NH B√ÅO: Model qu√° t·ª± tin (mean confidence > 0.99)\")\n",
    "    print(f\"      ‚Üí ƒê√¢y l√† d·∫•u hi·ªáu r√µ r√†ng c·ªßa overfitting!\")\n",
    "\n",
    "# 5. ƒê·ªÅ xu·∫•t gi·∫£i ph√°p\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí° ƒê·ªÄ XU·∫§T GI·∫¢I PH√ÅP CH·ªêNG OVERFITTING:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. ‚úÖ ƒê√É TH·ª∞C HI·ªÜN:\n",
    "   - Lo·∫°i b·ªè feature TIMESTAMP (REMOVE_TIMESTAMP_FEATURE = True)\n",
    "   - TƒÉng dropout t·ª´ 0.3 ‚Üí 0.5\n",
    "   - TƒÉng weight decay t·ª´ 1e-4 ‚Üí 1e-3\n",
    "   - Gi·∫£m learning rate t·ª´ 1e-3 ‚Üí 5e-4\n",
    "   - TƒÉng noise trong data augmentation\n",
    "\n",
    "2. üîß C·∫¶N TH·ª∞C HI·ªÜN TH√äM:\n",
    "   - Th√™m label smoothing trong loss function\n",
    "   - S·ª≠ d·ª•ng Mixup ho·∫∑c CutMix cho graph augmentation\n",
    "   - Th√™m feature dropout ri√™ng cho semantic features\n",
    "   - Gi·∫£m model capacity (hidden channels ho·∫∑c layers)\n",
    "   - Th√™m early stopping nghi√™m ng·∫∑t h∆°n\n",
    "   - S·ª≠ d·ª•ng validation set l·ªõn h∆°n\n",
    "\n",
    "3. üìä C·∫¢I THI·ªÜN DATASET:\n",
    "   - T·∫°o dataset ƒëa d·∫°ng h∆°n, kh√¥ng c√≥ pattern r√µ r√†ng\n",
    "   - Th√™m samples c√≥ c·∫£ CALL v√† TIMESTAMP\n",
    "   - Th√™m samples kh√¥ng c√≥ c·∫£ CALL v√† TIMESTAMP\n",
    "   - TƒÉng ƒë·ªô ph·ª©c t·∫°p c·ªßa synthetic bytecode\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n‚úÖ Ho√†n th√†nh ph√¢n t√≠ch overfitting!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c0f0173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Final Evaluation on Test Set\n",
      "============================================================\n",
      "\n",
      "Test Results:\n",
      "  Loss: 0.4441\n",
      "  Accuracy: 0.9970\n",
      "  Macro F1: 0.9970\n",
      "\n",
      "Per-class Metrics:\n",
      "  No Loop: Precision=1.0000, Recall=0.9940, F1=0.9970\n",
      "  Has Loop: Precision=0.9940, Recall=1.0000, F1=0.9970\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Loop     1.0000    0.9940    0.9970       500\n",
      "    Has Loop     0.9940    1.0000    0.9970       500\n",
      "\n",
      "    accuracy                         0.9970      1000\n",
      "   macro avg     0.9970    0.9970    0.9970      1000\n",
      "weighted avg     0.9970    0.9970    0.9970      1000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[497   3]\n",
      " [  0 500]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Confusion matrix saved to ./saved_models/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 9: Final Evaluation on Test Set\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Final Evaluation on Test Set\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(model, test_loader, criterion)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Macro F1: {test_f1:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(f\"\\nPer-class Metrics:\")\n",
    "for i, vuln_name in enumerate(TARGET_VULNS):\n",
    "    class_mask = (test_labels == i)\n",
    "    class_acc = (test_preds[class_mask] == test_labels[class_mask]).mean() if class_mask.sum() > 0 else 0\n",
    "    class_precision = precision_score(test_labels == i, test_preds == i, zero_division=0)\n",
    "    class_recall = recall_score(test_labels == i, test_preds == i, zero_division=0)\n",
    "    class_f1 = f1_score(test_labels == i, test_preds == i, zero_division=0)\n",
    "    print(f\"  {vuln_name}: Precision={class_precision:.4f}, Recall={class_recall:.4f}, F1={class_f1:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=TARGET_VULNS, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=TARGET_VULNS,\n",
    "            yticklabels=TARGET_VULNS)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix - HiFi-GraphSAGE ({DATASET_NAME})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_SAVE_DIR, 'confusion_matrix.png'), dpi=300)\n",
    "plt.show()\n",
    "print(f\"‚úì Confusion matrix saved to {MODEL_SAVE_DIR}/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90317d",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Evaluation\n",
    "\n",
    "Final evaluation with:\n",
    "- Per-class confusion matrices\n",
    "- Classification reports\n",
    "- Training history plots\n",
    "- ROC curves and AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "931f143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training History and Summary\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training history saved to ./saved_models/training_history.png\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "Model Configuration:\n",
      "  - Dataset: VSC\n",
      "  - Input features: 164\n",
      "  - Hidden channels: 32\n",
      "  - GraphSAGE layers: 2\n",
      "  - Total parameters: 12,610\n",
      "\n",
      "Training:\n",
      "  - Optimizer: Adam (lr=0.0003, weight_decay=0.002)\n",
      "  - Batch size: 64\n",
      "  - Epochs trained: 34\n",
      "  - Best Val F1: 1.0000\n",
      "\n",
      "Test Results:\n",
      "  - Accuracy: 0.9970\n",
      "  - Macro F1: 0.9970\n",
      "\n",
      "Files saved to ./saved_models:\n",
      "  - hifi_graphsage_vsc.pth (model weights)\n",
      "  - confusion_matrix.png\n",
      "  - training_history.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 10: Training History and Summary\n",
    "# =============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Training History and Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy/F1 plot\n",
    "axes[1].plot(history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "axes[1].plot(history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "axes[1].plot(history['val_f1'], 'g--', label='Val F1', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Training Progress')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_SAVE_DIR, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"‚úì Training history saved to {MODEL_SAVE_DIR}/training_history.png\")\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "Model Configuration:\n",
    "  - Dataset: {DATASET_NAME}\n",
    "  - Input features: {input_dim}\n",
    "  - Hidden channels: {HIDDEN_CHANNELS}\n",
    "  - GraphSAGE layers: {NUM_SAGE_LAYERS}\n",
    "  - Total parameters: {total_params:,}\n",
    "\n",
    "Training:\n",
    "  - Optimizer: Adam (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\n",
    "  - Batch size: {BATCH_SIZE}\n",
    "  - Epochs trained: {len(history['train_loss'])}\n",
    "  - Best Val F1: {best_val_f1:.4f}\n",
    "\n",
    "Test Results:\n",
    "  - Accuracy: {test_acc:.4f}\n",
    "  - Macro F1: {test_f1:.4f}\n",
    "\n",
    "Files saved to {MODEL_SAVE_DIR}:\n",
    "  - hifi_graphsage_{DATASET_NAME.lower()}.pth (model weights)\n",
    "  - confusion_matrix.png\n",
    "  - training_history.png\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a78242",
   "metadata": {},
   "source": [
    "## 11. K-Fold Cross-Validation\n",
    "\n",
    "ƒê·ªÉ ƒë·∫£m b·∫£o robustness c·ªßa model, th·ª±c hi·ªán k-fold cross-validation tr√™n to√†n b·ªô dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "804712d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "K-Fold Cross-Validation (K=5)\n",
      "============================================================\n",
      "\n",
      "========================================\n",
      "FOLD 1/5\n",
      "========================================\n",
      "Train: 8000 | Test: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9920 | Precision: 0.9921 | Recall: 0.9920 | F1: 0.9920\n",
      "\n",
      "========================================\n",
      "FOLD 2/5\n",
      "========================================\n",
      "Train: 8000 | Test: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000 | Precision: 1.0000 | Recall: 1.0000 | F1: 1.0000\n",
      "\n",
      "========================================\n",
      "FOLD 3/5\n",
      "========================================\n",
      "Train: 8000 | Test: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9940 | Precision: 0.9941 | Recall: 0.9940 | F1: 0.9940\n",
      "\n",
      "========================================\n",
      "FOLD 4/5\n",
      "========================================\n",
      "Train: 8000 | Test: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9850 | Precision: 0.9854 | Recall: 0.9850 | F1: 0.9850\n",
      "\n",
      "========================================\n",
      "FOLD 5/5\n",
      "========================================\n",
      "Train: 8000 | Test: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py:91: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9910 | Precision: 0.9912 | Recall: 0.9910 | F1: 0.9910\n",
      "\n",
      "============================================================\n",
      "K-FOLD CROSS-VALIDATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Metric                Mean        Std        Min        Max\n",
      "-------------------------------------------------------\n",
      "Accuracy            0.9924     0.0048     0.9850     1.0000\n",
      "Precision           0.9926     0.0047     0.9854     1.0000\n",
      "Recall              0.9924     0.0048     0.9850     1.0000\n",
      "F1 Score            0.9924     0.0048     0.9850     1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì K-fold results saved to ./saved_models/kfold_results.png\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 11: K-Fold Cross-Validation\n",
    "# =============================================================================\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"K-Fold Cross-Validation (K=5)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "K_FOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Prepare data\n",
    "all_labels = np.array([g.y.item() for g in all_graphs])\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(all_graphs, all_labels)):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"FOLD {fold + 1}/{K_FOLDS}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Split data\n",
    "    fold_train = [all_graphs[i] for i in train_idx]\n",
    "    fold_test = [all_graphs[i] for i in test_idx]\n",
    "    \n",
    "    # Augment training data\n",
    "    fold_train_aug = []\n",
    "    for g in fold_train:\n",
    "        fold_train_aug.append(g)\n",
    "        fold_train_aug.append(augment_graph(g, 0.08, 0.1))\n",
    "    \n",
    "    # Create loaders\n",
    "    fold_train_loader = DataLoader(fold_train_aug, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    fold_test_loader = DataLoader(fold_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(f\"Train: {len(fold_train_aug)} | Test: {len(fold_test)}\")\n",
    "    \n",
    "    # Initialize new model\n",
    "    fold_model = HiFiGraphSAGE(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=HIDDEN_CHANNELS,\n",
    "        output_dim=NUM_CLASSES,\n",
    "        num_layers=NUM_SAGE_LAYERS,\n",
    "        dropout=DROPOUT\n",
    "    ).to(device)\n",
    "    \n",
    "    fold_optimizer = Adam(fold_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    fold_criterion = LabelSmoothingCrossEntropy(smoothing=LABEL_SMOOTHING, weight=None)\n",
    "    \n",
    "    # Training loop\n",
    "    best_fold_f1 = 0\n",
    "    patience_count = 0\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        # Train\n",
    "        fold_model.train()\n",
    "        for batch in fold_train_loader:\n",
    "            batch = batch.to(device)\n",
    "            fold_optimizer.zero_grad()\n",
    "            logits = fold_model(batch)\n",
    "            loss = fold_criterion(logits, batch.y.squeeze())\n",
    "            loss.backward()\n",
    "            fold_optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        fold_model.eval()\n",
    "        all_preds, all_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in fold_test_loader:\n",
    "                batch = batch.to(device)\n",
    "                logits = fold_model(batch)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_true.extend(batch.y.squeeze().cpu().numpy())\n",
    "        \n",
    "        fold_f1 = f1_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "        \n",
    "        if fold_f1 > best_fold_f1:\n",
    "            best_fold_f1 = fold_f1\n",
    "            patience_count = 0\n",
    "        else:\n",
    "            patience_count += 1\n",
    "        \n",
    "        if patience_count >= PATIENCE:\n",
    "            break\n",
    "    \n",
    "    # Final evaluation\n",
    "    fold_model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in fold_test_loader:\n",
    "            batch = batch.to(device)\n",
    "            logits = fold_model(batch)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_true.extend(batch.y.squeeze().cpu().numpy())\n",
    "    \n",
    "    fold_acc = np.mean(np.array(all_preds) == np.array(all_true))\n",
    "    fold_f1 = f1_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "    fold_precision = precision_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "    fold_recall = recall_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': fold_acc,\n",
    "        'precision': fold_precision,\n",
    "        'recall': fold_recall,\n",
    "        'f1': fold_f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {fold_acc:.4f} | Precision: {fold_precision:.4f} | Recall: {fold_recall:.4f} | F1: {fold_f1:.4f}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"K-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "accs = [r['accuracy'] for r in fold_results]\n",
    "precs = [r['precision'] for r in fold_results]\n",
    "recs = [r['recall'] for r in fold_results]\n",
    "f1s = [r['f1'] for r in fold_results]\n",
    "\n",
    "print(f\"\\n{'Metric':<15} {'Mean':>10} {'Std':>10} {'Min':>10} {'Max':>10}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Accuracy':<15} {np.mean(accs):>10.4f} {np.std(accs):>10.4f} {np.min(accs):>10.4f} {np.max(accs):>10.4f}\")\n",
    "print(f\"{'Precision':<15} {np.mean(precs):>10.4f} {np.std(precs):>10.4f} {np.min(precs):>10.4f} {np.max(precs):>10.4f}\")\n",
    "print(f\"{'Recall':<15} {np.mean(recs):>10.4f} {np.std(recs):>10.4f} {np.min(recs):>10.4f} {np.max(recs):>10.4f}\")\n",
    "print(f\"{'F1 Score':<15} {np.mean(f1s):>10.4f} {np.std(f1s):>10.4f} {np.min(f1s):>10.4f} {np.max(f1s):>10.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(K_FOLDS)\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x - 1.5*width, accs, width, label='Accuracy', color='blue', alpha=0.7)\n",
    "plt.bar(x - 0.5*width, precs, width, label='Precision', color='green', alpha=0.7)\n",
    "plt.bar(x + 0.5*width, recs, width, label='Recall', color='orange', alpha=0.7)\n",
    "plt.bar(x + 1.5*width, f1s, width, label='F1', color='red', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('K-Fold Cross-Validation Results')\n",
    "plt.xticks(x, [f'Fold {i+1}' for i in range(K_FOLDS)])\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_SAVE_DIR, 'kfold_results.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì K-fold results saved to {MODEL_SAVE_DIR}/kfold_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158978b8",
   "metadata": {},
   "source": [
    "## 12. Real Bytecode Testing with Solc\n",
    "\n",
    "Test the model on **real bytecode** compiled from actual Solidity contracts using `solc`.\n",
    "\n",
    "### Prerequisites:\n",
    "- Install solc: `pip install py-solc-x` or download from [solidity releases](https://github.com/ethereum/solidity/releases)\n",
    "- The model will be tested on both:\n",
    "  1. **Real vulnerable contracts** from the dataset\n",
    "  2. **Custom test contracts** written specifically for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc6e69ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Real Bytecode Testing with Solc\n",
      "============================================================\n",
      "‚ö† solc not found in PATH. Trying py-solc-x...\n",
      "‚úì py-solc-x installed, using solc 0.8.20\n",
      "\n",
      "‚úì Defined 3 test contracts\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 12: Real Bytecode Testing with Solc\n",
    "# =============================================================================\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Real Bytecode Testing with Solc\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if solc is available\n",
    "solc_path = shutil.which(\"solc\")\n",
    "if solc_path:\n",
    "    print(f\"‚úì Found solc at: {solc_path}\")\n",
    "    result = subprocess.run([\"solc\", \"--version\"], capture_output=True, text=True)\n",
    "    version_line = [l for l in result.stdout.split('\\n') if 'Version' in l]\n",
    "    if version_line:\n",
    "        print(f\"  {version_line[0]}\")\n",
    "else:\n",
    "    print(\"‚ö† solc not found in PATH. Trying py-solc-x...\")\n",
    "    try:\n",
    "        import solcx\n",
    "        solcx.install_solc('0.8.20')\n",
    "        solcx.set_solc_version('0.8.20')\n",
    "        print(f\"‚úì py-solc-x installed, using solc 0.8.20\")\n",
    "        solc_path = \"py-solc-x\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Could not initialize solc: {e}\")\n",
    "        print(\"  Please install solc manually or run: pip install py-solc-x\")\n",
    "        solc_path = None\n",
    "\n",
    "# Define test contracts\n",
    "TEST_CONTRACTS = {\n",
    "    \"reentrancy_vulnerable\": {\n",
    "        \"code\": '''\n",
    "// SPDX-License-Identifier: MIT\n",
    "pragma solidity ^0.8.0;\n",
    "\n",
    "contract ReentrancyVulnerable {\n",
    "    mapping(address => uint256) public balances;\n",
    "    \n",
    "    function deposit() public payable {\n",
    "        balances[msg.sender] += msg.value;\n",
    "    }\n",
    "    \n",
    "    function withdraw() public {\n",
    "        uint256 balance = balances[msg.sender];\n",
    "        require(balance > 0, \"No balance\");\n",
    "        \n",
    "        // Vulnerable: external call before state update\n",
    "        (bool success, ) = msg.sender.call{value: balance}(\"\");\n",
    "        require(success, \"Transfer failed\");\n",
    "        \n",
    "        balances[msg.sender] = 0;\n",
    "    }\n",
    "}\n",
    "''',\n",
    "        \"expected_label\": 1,  # Re-entrancy (class 1)\n",
    "        \"vulnerability\": \"Re-entrancy\"\n",
    "    },\n",
    "    \"overflow_vulnerable\": {\n",
    "        \"code\": '''\n",
    "// SPDX-License-Identifier: MIT\n",
    "pragma solidity ^0.8.0;\n",
    "\n",
    "contract OverflowVulnerable {\n",
    "    uint8 public count = 0;\n",
    "    \n",
    "    function increment(uint8 amount) public {\n",
    "        // In Solidity 0.8+, this would revert on overflow\n",
    "        // But for older versions or unchecked blocks, this is vulnerable\n",
    "        unchecked {\n",
    "            count += amount;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    function decrement(uint8 amount) public {\n",
    "        unchecked {\n",
    "            count -= amount;  // Underflow vulnerability\n",
    "        }\n",
    "    }\n",
    "}\n",
    "''',\n",
    "        \"expected_label\": 0,  # Overflow-Underflow (class 0)\n",
    "        \"vulnerability\": \"Overflow-Underflow\"\n",
    "    },\n",
    "    \"safe_contract\": {\n",
    "        \"code\": '''\n",
    "// SPDX-License-Identifier: MIT\n",
    "pragma solidity ^0.8.0;\n",
    "\n",
    "contract SafeContract {\n",
    "    mapping(address => uint256) public balances;\n",
    "    bool private locked;\n",
    "    \n",
    "    modifier noReentrant() {\n",
    "        require(!locked, \"No re-entrancy\");\n",
    "        locked = true;\n",
    "        _;\n",
    "        locked = false;\n",
    "    }\n",
    "    \n",
    "    function deposit() public payable {\n",
    "        balances[msg.sender] += msg.value;\n",
    "    }\n",
    "    \n",
    "    function withdraw() public noReentrant {\n",
    "        uint256 balance = balances[msg.sender];\n",
    "        require(balance > 0, \"No balance\");\n",
    "        \n",
    "        balances[msg.sender] = 0;  // State update before call\n",
    "        \n",
    "        (bool success, ) = msg.sender.call{value: balance}(\"\");\n",
    "        require(success, \"Transfer failed\");\n",
    "    }\n",
    "}\n",
    "''',\n",
    "        \"expected_label\": -1,  # Safe (unknown - depends on training)\n",
    "        \"vulnerability\": \"None (Safe)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\n‚úì Defined {len(TEST_CONTRACTS)} test contracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db9bc993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py-solc-x in /usr/local/lib/python3.12/dist-packages (2.0.5)\n",
      "Requirement already satisfied: requests<3,>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from py-solc-x) (2.32.4)\n",
      "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from py-solc-x) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.19.0->py-solc-x) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.19.0->py-solc-x) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.19.0->py-solc-x) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.19.0->py-solc-x) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install py-solc-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e28f0bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Using solc version: 0.8.20\n",
      "\n",
      "Compiling test contracts...\n",
      "\n",
      "‚úì reentrancy_vulnerable: 2486 bytes\n",
      "‚úì overflow_vulnerable: 912 bytes\n",
      "‚úì safe_contract: 2952 bytes\n",
      "\n",
      "‚úì Compiled 3 contracts\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Compile contracts and get real bytecode\n",
    "# =============================================================================\n",
    "from typing import Optional\n",
    "\n",
    "# Install solc if using py-solc-x\n",
    "try:\n",
    "    import solcx\n",
    "    installed_versions = solcx.get_installed_solc_versions()\n",
    "    if not any('0.8' in str(v) for v in installed_versions):\n",
    "        print(\"Installing solc 0.8.20...\")\n",
    "        solcx.install_solc('0.8.20')\n",
    "    solcx.set_solc_version('0.8.20')\n",
    "    print(f\"‚úì Using solc version: {solcx.get_solc_version()}\")\n",
    "    SOLCX_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö† py-solc-x not installed, will try command-line solc\")\n",
    "    SOLCX_AVAILABLE = False\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† solcx setup error: {e}\")\n",
    "    SOLCX_AVAILABLE = False\n",
    "\n",
    "def compile_with_solc(source_code: str, contract_name: str) -> Optional[str]:\n",
    "    \"\"\"Compile Solidity source code to bytecode using solc.\"\"\"\n",
    "    try:\n",
    "        # Try py-solc-x first\n",
    "        if SOLCX_AVAILABLE:\n",
    "            try:\n",
    "                import solcx\n",
    "                compiled = solcx.compile_source(\n",
    "                    source_code,\n",
    "                    output_values=['bin', 'bin-runtime']\n",
    "                )\n",
    "                # Get the contract bytecode\n",
    "                for key in compiled:\n",
    "                    if contract_name in key:\n",
    "                        return compiled[key].get('bin-runtime', compiled[key].get('bin', ''))\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"  solcx compile error: {e}\")\n",
    "        \n",
    "        # Fallback to command-line solc\n",
    "        import tempfile\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.sol', delete=False) as f:\n",
    "            f.write(source_code)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['solc', '--bin-runtime', temp_path],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                print(f\"  Solc error: {result.stderr[:100]}\")\n",
    "                return None\n",
    "            \n",
    "            # Parse output to get bytecode\n",
    "            lines = result.stdout.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if 'Binary of the runtime part' in line or '=======' in line:\n",
    "                    if i + 2 < len(lines) and lines[i + 2].strip():\n",
    "                        return lines[i + 2].strip()\n",
    "            \n",
    "            # Alternative: look for hex string\n",
    "            for line in lines:\n",
    "                if line.strip() and all(c in '0123456789abcdefABCDEF' for c in line.strip()):\n",
    "                    return line.strip()\n",
    "            \n",
    "            return None\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Compilation error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Compile test contracts\n",
    "compiled_contracts = {}\n",
    "\n",
    "print(\"\\nCompiling test contracts...\\n\")\n",
    "\n",
    "for name, info in TEST_CONTRACTS.items():\n",
    "    contract_name = name.replace('_', ' ').title().replace(' ', '')\n",
    "    bytecode = compile_with_solc(info['code'], contract_name)\n",
    "    \n",
    "    if bytecode and len(bytecode) > 10:\n",
    "        compiled_contracts[name] = {\n",
    "            'bytecode': bytecode,\n",
    "            'expected_label': info['expected_label'],\n",
    "            'vulnerability': info['vulnerability']\n",
    "        }\n",
    "        print(f\"‚úì {name}: {len(bytecode)} bytes\")\n",
    "    else:\n",
    "        print(f\"‚úó {name}: Compilation failed or empty bytecode\")\n",
    "        # Use synthetic bytecode as fallback\n",
    "        compiled_contracts[name] = {\n",
    "            'bytecode': generate_synthetic_bytecode(info['expected_label'] if info['expected_label'] >= 0 else 0),\n",
    "            'expected_label': info['expected_label'],\n",
    "            'vulnerability': info['vulnerability'],\n",
    "            'synthetic': True\n",
    "        }\n",
    "        print(f\"  ‚Üí Using synthetic bytecode as fallback\")\n",
    "\n",
    "print(f\"\\n‚úì Compiled {len(compiled_contracts)} contracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cc454ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing Model on Real/Compiled Bytecode\n",
      "============================================================\n",
      "\n",
      "Contract                  Expected             Predicted            Confidence   Status\n",
      "------------------------------------------------------------------------------------------\n",
      "reentrancy_vulnerable     Re-entrancy          ERROR                N/A          ‚úó index 14 is out of bounds for \n",
      "overflow_vulnerable       Overflow-Underflow   ERROR                N/A          ‚úó index 14 is out of bounds for \n",
      "safe_contract             None (Safe)          ERROR                N/A          ‚úó index 14 is out of bounds for \n",
      "\n",
      "============================================================\n",
      "REAL BYTECODE TESTING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Contracts tested: 0\n",
      "Known vulnerability labels: 0\n",
      "\n",
      "Average confidence: nan\n",
      "\n",
      "[S] = Synthetic bytecode (fallback when solc compilation failed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Test model on real bytecode\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Model on Real/Compiled Bytecode\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load the best model\n",
    "# model.load_state_dict(torch.load(os.path.join(MODEL_SAVE_DIR, 'hifi_gat.pth'), map_location=device))\n",
    "checkpoint = torch.load(os.path.join(MODEL_SAVE_DIR, f'hifi_graphsage_{DATASET_NAME.lower()}.pth'), map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "# Class names\n",
    "class_names = TARGET_VULNS\n",
    "\n",
    "results = []\n",
    "def bytecode_to_graph(cfg_builder, bytecode_hex, label=0):\n",
    "    instructions = cfg_builder.disassemble_bytecode(bytecode_hex)\n",
    "    cfg = cfg_builder.build_cfg(instructions)\n",
    "    data = cfg_builder.cfg_to_pyg_data(cfg)\n",
    "    if data is not None:\n",
    "        data.y = torch.tensor([label], dtype=torch.long)\n",
    "    return data\n",
    "\n",
    "print(f\"\\n{'Contract':<25} {'Expected':<20} {'Predicted':<20} {'Confidence':<12} {'Status'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for name, info in compiled_contracts.items():\n",
    "    bytecode = info['bytecode']\n",
    "    expected = info['expected_label']\n",
    "    vuln_type = info['vulnerability']\n",
    "    is_synthetic = info.get('synthetic', False)\n",
    "    \n",
    "    # Build CFG and convert to graph\n",
    "    try:\n",
    "        cfg_builder = HiFiCFGBuilder()\n",
    "        graph = bytecode_to_graph(cfg_builder, bytecode, label=0)  # Label doesn't matter for inference\n",
    "        \n",
    "        if graph is not None:\n",
    "            # Ensure graph has correct dimensions\n",
    "            if graph.x.shape[1] != input_dim:\n",
    "                # Pad or truncate features\n",
    "                if graph.x.shape[1] < input_dim:\n",
    "                    padding = torch.zeros(graph.x.shape[0], input_dim - graph.x.shape[1])\n",
    "                    graph.x = torch.cat([graph.x, padding], dim=1)\n",
    "                else:\n",
    "                    graph.x = graph.x[:, :input_dim]\n",
    "            \n",
    "            # Create batch\n",
    "            batch = Batch.from_data_list([graph]).to(device)\n",
    "            \n",
    "            # Predict\n",
    "            with torch.no_grad():\n",
    "                logits = model(batch)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                pred = logits.argmax(dim=1).item()\n",
    "                confidence = probs[0, pred].item()\n",
    "            \n",
    "            pred_label = class_names[pred]\n",
    "            \n",
    "            # Check if prediction matches expected (skip for safe contracts)\n",
    "            if expected >= 0:\n",
    "                status = \"‚úì CORRECT\" if pred == expected else \"‚úó WRONG\"\n",
    "            else:\n",
    "                status = \"? (Safe contract)\"\n",
    "            \n",
    "            synthetic_marker = \" [S]\" if is_synthetic else \"\"\n",
    "            \n",
    "            results.append({\n",
    "                'name': name,\n",
    "                'expected': vuln_type,\n",
    "                'predicted': pred_label,\n",
    "                'confidence': confidence,\n",
    "                'correct': pred == expected if expected >= 0 else None\n",
    "            })\n",
    "            \n",
    "            print(f\"{name + synthetic_marker:<25} {vuln_type:<20} {pred_label:<20} {confidence:.4f}       {status}\")\n",
    "        else:\n",
    "            print(f\"{name:<25} {vuln_type:<20} {'N/A':<20} {'N/A':<12} ‚úó Graph build failed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"{name:<25} {vuln_type:<20} {'ERROR':<20} {'N/A':<12} ‚úó {str(e)[:30]}\")\n",
    "\n",
    "# Summary\n",
    "correct = sum(1 for r in results if r['correct'] == True)\n",
    "total_known = sum(1 for r in results if r['correct'] is not None)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REAL BYTECODE TESTING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nContracts tested: {len(results)}\")\n",
    "print(f\"Known vulnerability labels: {total_known}\")\n",
    "print(f\"Correctly classified: {correct}/{total_known} ({100*correct/total_known:.1f}%)\" if total_known > 0 else \"\")\n",
    "print(f\"Average confidence: {np.mean([r['confidence'] for r in results]):.4f}\")\n",
    "\n",
    "print(\"\\n[S] = Synthetic bytecode (fallback when solc compilation failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32587032",
   "metadata": {},
   "source": [
    "## 13. Final Summary\n",
    "\n",
    "### Model Architecture\n",
    "- **HiFi-GraphSAGE** with 2 GraphSAGE layers, 64 hidden channels\n",
    "- **165-dimensional node features**: 150 BoW (EVM opcodes) + 15 semantic features\n",
    "- **Total parameters**: ~40K\n",
    "\n",
    "### Datasets\n",
    "- **ESC Dataset**: Re-entrancy (call.value) v√† Timestamp Dependence (block.timestamp)\n",
    "- **VSC Dataset**: Loop Statements detection\n",
    "\n",
    "### Training Configuration  \n",
    "- **Optimizer**: Adam (lr=1e-3, weight_decay=1e-4)\n",
    "- **Loss**: CrossEntropyLoss\n",
    "- **Early Stopping**: Patience=20 epochs\n",
    "\n",
    "### Validation Methods\n",
    "1. **Hold-out Test Set**: 80/20 train/test split\n",
    "2. **K-Fold Cross-Validation**: 5-fold stratified CV\n",
    "3. **Real Bytecode Testing**: Compile with solc and test\n",
    "\n",
    "### Notes\n",
    "- Model trained on synthetic bytecode patterns\n",
    "- For production use, train on real compiled contracts from verified sources\n",
    "- Consider augmenting with more diverse vulnerability patterns\n",
    "- GraphSAGE provides inductive learning capability for unseen graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
