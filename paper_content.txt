DecSmart: Detecting Smart Contract
Vulnerabilities using GraphSAGE on High-Fidelity
Control Flow Graphs
Tan-Gia-Quoc Pham
1,2, Nhut-Thien Phan1,2, and Tuan-Dung Tran
1,2
University of Information Technology, Ho Chi Minh City, Vietnam1
Vietnam National University, Ho Chi Minh City, Vietnam2
{23521308, 23521487}@gm.uit.edu.vn, dungtrt@uit.edu.vn
Abstract. Smart contracts are a fundamental component of decentral-
ized finance systems, where security vulnerabilities can lead to irreversible
financial losses. Existing vulnerability detection techniques face inherent
trade-offs: static analysis scales efficiently but suffers from high false-
positive rates, while symbolic execution provides higher precision at the
cost of substantial computational overhead. Recent Graph Neural Net-
work (GNN)-based approaches have shown promising results on synthetic
benchmarks; however, we identify a critical generalization gap where these
models overfit fixed vulnerability templates in synthetic data, leading
to significant performance degradation on real-world contracts. In this
paper, we propose DecSmart, an inductive smart contract vulnerability
detection framework based on GraphSAGE and High-Fidelity Control
Flow Graphs. Unlike transductive methods that memorize graph struc-
tures, our framework learns transferable representations by preserving
opcode- and operand-level semantics. Experiments reveal a performance
inversion: while state-of-the-art baselines dominate on synthetic data
but falter in the wild, DecSmart demonstrates superior generalization,
achieving a competitive F1-score of 0.828 on real-world datasets. These
results confirm that the proposed approach effectively balances detection
accuracy and generalization for practical smart contract auditing.
Keywords: Blockchain · Smart Contracts · Vulnerability Detection ·
Control Flow Graph · GraphSAGE · Graph Neural Networks
1
Introduction
Smart contracts on blockchains like Ethereum [15,16] are immutable; a single bug
can lead to irreversible financial losses, as demonstrated by the infamous DAO
incident [1,10]. Therefore, effective pre-deployment auditing is non-negotiable.
Current detection methods have distinct limitations. Static analysis tools,
such as Slither [2], are fast but generate too many false alarms, as reported in
empirical studies [4]. Conversely, symbolic execution tools like Oyente [9] and
Mythril [11] provide higher precision but suffer from path explosion, making
them computationally expensive and slow for complex contracts.
2
Tan-Gia-Quoc Pham et al.
To address these issues, Deep Learning approaches have been adopted, evolv-
ing from sequence-based models [3] to Graph Neural Networks (GNNs) that
capture code semantics [17,18]. However, most existing GNN models are trans-
ductive [8,12,14]. They assume a fixed graph structure during training, which
makes them prone to overfitting synthetic patterns and unable to generalize to
new, unseen contracts in the wild [7].
We propose DecSmart, an inductive vulnerability detection framework de-
signed for real-world application. By combining High-Fidelity Control Flow
Graphs with GraphSAGE [6], DecSmart learns to recognize transferable vulnera-
bility patterns rather than memorizing specific code structures.
Our key contributions are summarized as follows:
– We introduce DecSmart, which uses GraphSAGE to handle unseen contracts
efficiently without retraining.
– We design a graph structure that retains fine-grained opcode and operand
semantics for precise analysis.
– Experiments show DecSmart achieves a competitive F1-score of 0.828 on real-
world datasets, proving its practical superiority over transductive baselines.
– We empirically demonstrate a "performance inversion" where state-of-the-art
transductive models excel on synthetic data but fail on real contracts due to
overfitting.
2
Related work
We categorize existing vulnerability detection approaches into two main streams:
traditional methods based on static analysis and symbolic execution, and emerging
data-driven methods based on Deep Learning.
Table 1. Comparison of related works and our proposed approach.
Method
Technique
Representation Key Limitation
Oyente [9]
Symbolic Exec.
CFG
Path explosion, Low coverage
Slither [2]
Static Analysis
IR (SlithIR)
Rule-based, High False Positives
Mythril [11]
Concolic Analysis
Bytecode
Slow, Scalability issues
SmartEmbed [3] DL (Att-LSTM)
Code Sequence
Ignores structural info
TMP [18]
GNN
Contract Graph Simplified node features
AME [8]
GNN + RNN
Graph + Seq
Feature loss in simple graphs
DecSmart
GraphSAGE
HiFi-CFG
Time Overhead +
Bytecode Dependency
2.1
Traditional vulnerability detection
Traditional tools primarily rely on defining rigid rules or exploring execution
paths mathematically to identify bugs.
DecSmart: Smart Contract Vulnerability Detection
3
Symbolic Execution and Concolic Analysis. Oyente [9] is one of the
pioneering tools that utilizes symbolic execution to simulate path traversal in the
Control Flow Graph (CFG). It effectively detects vulnerabilities like Reentrancy
and Timestamp Dependence but suffers from the path explosion problem, leading
to low code coverage. To improve precision, Mythril [11] combines concolic
analysis (concrete + symbolic execution) with taint analysis. While more precise
than Oyente, Mythril is computationally expensive and time-consuming when
analyzing complex contracts with deep execution trees.
Static Analysis. Slither [2] converts Solidity code into an intermediate
representation (SlithIR) and applies static analysis techniques like data flow and
taint tracking. Although Slither is significantly faster than symbolic execution
tools, its reliance on pre-defined vulnerability patterns (rule-based) makes it
prone to high false-positive rates and unable to detect novel or logic-specific bugs
that deviate from known signatures.
2.2
Deep learning-based detection
To overcome the reliance on manual rules and expert knowledge, researchers have
adopted Deep Learning to learn vulnerability features automatically from source
code or bytecode.
Sequence-based Models. Early approaches like SmartEmbed [3] treat
smart contract code as sequential text. They utilize word embedding techniques
(e.g., Word2Vec, FastText) combined with sequence models (like LSTM or GRU)
to classify code snippets. However, these methods treat code merely as text,
largely ignoring the structural information (control flow and data flow) inherent
in the program, leading to suboptimal performance on complex logic.
Graph-based Models (GNNs). Recognizing the importance of code struc-
ture, recent works represent contracts as graphs. TMP (Temporal Message
Propagation) [18] constructs a contract graph where nodes represent critical
functions or variables and applies GNNs to capture structural dependencies.
Similarly, AME (Attentive Multi-Encoder) [8] combines graph representations
with sequence encoders to capture both local and global context. Although GNN-
based methods like TMP and AME outperform sequence models, they often
rely on simplified graph representations where node features are initialized using
basic one-hot encoding or simple embeddings. However, these methods have not
fully utilized the rich semantic information embedded within complex CFGs, a
limitation that this paper aims to address by introducing High-Fidelity CFGs.
3
Methodology
We propose a comprehensive framework for smart contract vulnerability detection,
integrated into a web-based analysis tool. Figure 1 illustrates the overall system
architecture, which consists of two main layers: a Frontend Layer for code
interaction and visualization, and a Backend Layer for deep learning-based
security analysis.
4
Tan-Gia-Quoc Pham et al.
Frontend Layer
Backend Layer
User
React App
(UI)
Code Editor
(Monaco)
Parser &
CFG Builder
CFG
Visualizer
Flask API
Gateway
Route
Definitions
Security
Analyzer
HiFi-SAGE
Model
Node Helper
Service
Input
AST
Graph Data
HTTP Req
Bytecode
Vulnerability Report
Fig. 1. The proposed system architecture. The diagram highlights the interaction
between the Frontend visualization tools and the Backend HiFi-SAGE engine.
The system architecture, illustrated in Fig. 1, is organized into two distinct
logical layers: the Frontend for user interaction and visualization, and the Backend
for deep semantic analysis. The workflow begins when the User submits smart
contract code via the React App (UI). This input is managed by the Monaco
Code Editor, which interacts with the Parser & CFG Builder to generate an
Abstract Syntax Tree (AST). When an analysis is triggered, the source code is
transmitted to the Flask API Gateway. The request is routed to the Security
Analyzer, where Solidity code is compiled and disassembled into EVM Bytecode.
This bytecode acts as the primary input for our core engine, the HiFi-SAGE
Model. The prediction results follow the return path as a "Vulnerability Report".
3.1
High-fidelity control flow graph construction
The first phase involves transforming the smart contract bytecode into a structured
graph representation. We adopt a High-Fidelity Control Flow Graph (HF-CFG)
approach:
Disassembly and basic block identification. The raw EVM bytecode is
first disassembled into a sequence of opcodes. We then partition this sequence
into basic blocks—linear sequences of instructions with a single entry point and a
single exit point. This partitioning is critical for reducing the graph size while
maintaining the contract’s logical structure [18].
Graph definition. Formally, the HF-CFG is defined as a directed graph G =
(V, E), where:
DecSmart: Smart Contract Vulnerability Detection
5
– Nodes (V): Each node vi ∈V represents a basic block enriched with full
semantic content.
– Edges (E): A directed edge eij = (vi, vj) ∈E exists if the control flow
can transition from block vi to block vj, determined by analyzing jump
instructions.
High-fidelity feature extraction. We extract a feature vector for each node
representing:
1. Opcode Semantics: Pre-trained embeddings (Word2Vec/FastText) convert
EVM opcodes into dense vectors.
2. Operand Information: Critical operands are encoded to distinguish between
different invocations.
3.2
GraphSAGE for inductive detection
To efficiently capture semantic dependencies and generalize across unseen smart
contracts, we employ GraphSAGE [6]. Unlike transductive approaches (e.g.,
GCN) that require the entire graph structure during training, GraphSAGE learns
aggregator functions that can generate embeddings for unseen nodes.
Neighborhood aggregation. For each node v ∈V, let hk
v denote the hidden
state of node v at the k-th layer. We initialize h0
v with the extracted high-fidelity
features. At each iteration k, the model aggregates information from the local
neighborhood N(v) as follows:
hk
N(v) = MEAN
 
hk−1
u
, ∀u ∈N(v)
	
(1)
where MEAN(·) serves as the aggregator function, ensuring the operation is
permutation invariant and efficient for large-scale graphs.
Feature update. The aggregated neighborhood vector hk
N(v) is then concate-
nated with the node’s current representation hk−1
v
and passed through a fully
connected layer with a non-linear activation function σ (e.g., ReLU):
hk
v = σ

Wk · CONCAT

hk−1
v
, hk
N(v)

(2)
Here, Wk represents the trainable weight matrix at layer k. The resulting
embedding hk
v is normalized: hk
v ←hk
v/∥hk
v∥2 to stabilize training.
Graph-level classification. After K layers of aggregation, each node contains
information from its K-hop neighborhood. To obtain a global representation hG
for the entire smart contract graph, we apply a Readout function (Global Mean
Pooling) followed by a Multi-Layer Perceptron (MLP) for the final prediction:
6
Tan-Gia-Quoc Pham et al.
hk−1
v
u1
u2
u3
1. Neighbor Sampling
AGGREGATE
(Mean/LSTM)
UPDATE
(Concat + MLP)
Self
Neighbor
hk
v
Phase 1: GraphSAGE Inductive Convolution
hK
1
hK
2
hK
N
All Nodes
READOUT
(Global Mean/Max)
MLP
Classifier
hG
ˆy
Prob.
Phase 2: Graph Classification
Fig. 2. The detailed architecture of DecSmart. The Inductive GraphSAGE layer (left)
aggregates local neighborhood information to update node embeddings. These embed-
dings are then pooled globally (right) to classify the smart contract.
hG = 1
|V|
X
v∈V
hK
v ;
ˆy = Softmax (MLP(hG))
(3)
This hierarchical process allows DecSmart to learn structural vulnerability
patterns that are independent of specific node identities, facilitating the inductive
generalization observed in our experiments.
4
Experimental results
4.1
Experimental setup
Dataset We evaluate our proposed DecSmart framework using SolidiFi Bench-
mark [4] denoted as SolidiFi — a widely-used dataset containing 9,369 contracts
where vulnerabilities are injected using fixed templates into benign code. This
dataset tests the model’s ability to recognize standard vulnerability patterns,
and the real-world VNT Chain Smart Contract (VSC) dataset (compatible with
EVM), sourced from the GNNSCVulDetector repository [5]. The VSC dataset
consists of 13,761 functions collected from 4,170 smart contracts deployed on the
VNT Chain network [13,8]. This dataset is specifically chosen for its heterogeneity
and complexity, representing real-world deployment scenarios. Unlike synthetic
benchmarks like SolidiFi, VSC comprises contracts collected from the mainnet
and labeled using a combination of automated tools and manual verification,
providing a robust testbed for evaluating generalization capabilities.
Implementation details All experiments were conducted on a workstation equipped
with an AMD Ryzen 7 6800H CPU and an RTX 3050 GPU. The framework
utilizes Python 3.13 and PyTorch Geometric. We compare DecSmart against
traditional tools (Oyente, Mythril, Slither) and SOTA deep learning models
(SmartEmbed, TMP, AME). To prevent overfitting on the synthetic patterns of
the training data, we adopted a lightweight architecture with 32 hidden channels
and applied strong regularization techniques, including a dropout rate of 0.6
and weight decay of 2 × 10−3. We also removed the explicit timestamp feature
DecSmart: Smart Contract Vulnerability Detection
7
Table 2. Hyperparameter Configuration for DecSmart.
Parameter
Value
Model Architecture
Input Feature Dimension 164 (Timestamp removed)
GraphSAGE Layers
2
Hidden Channels
32
Aggregator Type
Mean
Dropout Rate
0.6
Total Parameters
∼12,610
Training Optimization
Optimizer
Adam
Learning Rate
3 × 10−4
Weight Decay (L2)
2 × 10−3
Batch Size
64
Loss Function
Label Smoothing (0.3)
Early Stopping Patience
20 epochs
(reducing input dimensions to 164) to force the model to learn structural depen-
dencies rather than relying on specific opcodes. The model was trained using the
Adam optimizer with a learning rate of 3 × 10−4 and label smoothing of 0.3 for
robustness.
To evaluate the effectiveness of DecSmart, we compare it against six repre-
sentative methods:
– Traditional Tools: Oyente [9], Mythril [11], and Slither [2].
– Learning-based Models: The sequence-based model SmartEmbed [3], and
state-of-the-art graph-based models TMP [18] and AME [8].
The baseline results for AME, TMP, and other tools are cited directly from the
comparative study in [8].
4.2
Performance comparison
Table 3 presents the performance on the SolidiFI benchmark. We observe that
existing deep learning models (TMP, AME) achieve extremely high F1-Scores
(> 0.93), whereas DecSmart achieves a modest 0.515.
The performance of the different methods on the VSC dataset is presented in
Table 4.
Analysis As shown in Table 4, deep learning-based methods generally outperform
traditional symbolic execution tools (Oyente, Mythril) in terms of F1-Score on
real-world data. While AME achieves a slightly higher F1-score (0.836) compared
to DecSmart (0.828), it relies on a complex hybrid architecture (GNN+RNN)
that requires computationally expensive graph-sequence alignment.
8
Tan-Gia-Quoc Pham et al.
Table 3. Overall Performance Comparison on SolidiFI Benchmark.
Group
Method
Precision Recall F1-Score Acc
Non-ML
Oyente
0.702
0.105
0.182
0.553
Slither
0.634
0.552
0.590
0.601
Mythril
0.921
0.128
0.224
0.589
ML/GNN
SmartEmbed
0.912
0.885
0.898
0.902
TMP
0.938
0.932
0.935
0.936
AME
0.941
0.928
0.934
0.935
HiFi-SAGE DecSmart
0.542
0.490
0.515
N/A
Table 4. Overall Performance Comparison on VSC Dataset.
Group
Method
Precision Recall F1-Score Acc Time (s)
Non-ML
Oyente [9]
0.417
0.466
0.433
0.605
∼15
Slither [2]
0.634
0.552
0.590
0.601
< 1
Mythril [11]
0.448
0.567
0.483
0.608
> 180
ML/GNN
SmartEmbed [3]
0.775
0.832
0.802
0.814
∼0.3
TMP [18]
0.743
0.803
0.771
0.808
∼0.5
AME [8]
0.823
0.850
0.836
0.857
∼0.6
HiFi-SAGE DecSmart
0.842
0.815
0.828
0.831
∼1.13
Regarding time efficiency, although DecSmart’s reported time (∼1.13s) ap-
pears higher than AME (∼0.6s), it represents the end-to-end latency (including
bytecode disassembly, HiFi-CFG construction, and inference) on consumer-grade
hardware. In contrast, baseline methods often report only model inference time,
excluding the heavy preprocessing costs. Furthermore, DecSmart utilizes induc-
tive GraphSAGE, allowing it to scan newly deployed contracts immediately
without the retraining or full-graph re-indexing required by transductive methods
like TMP. This offers a superior trade-off between accuracy and operational
scalability for real-time auditing pipelines.
4.3
Discussion: the synthetic-to-real generalization gap
A critical finding from our experiments is the performance inversion observed
between the synthetic and real-world datasets.
On SolidiFI, baselines like TMP and AME perform exceptionally well. We
hypothesize that these transductive models tend to overfit to the repetitive,
fixed vulnerability templates used to generate the synthetic data. In contrast,
DecSmart, which relies on inductive GraphSAGE to aggregate neighborhood
semantics, struggles to "memorize" these rigid syntactic patterns, resulting in
lower scores.
However, on the real-world VSC dataset, the performance of TMP drops
drastically (F1 0.935 →0.771), indicating poor generalization to the unseen,
DecSmart: Smart Contract Vulnerability Detection
9
heterogeneous code structures found in the wild. DecSmart, conversely, demon-
strates remarkable robustness, achieving a high F1-score of 0.828 on real data.
This suggests that DecSmart learns generalized structural representations of
vulnerabilities rather than memorizing superficial syntax.
5
Conclusion and future work
In this paper, we proposed DecSmart, a framework that leverages GraphSAGE
on High-Fidelity Control Flow Graphs. By enriching graph nodes with semantic
operand information and utilizing inductive graph convolution, our approach
captures complex execution logic efficiently. Experimental results on real-world
Ethereum smart contracts demonstrate that DecSmart achieves a strong F1-Score
of 0.828, surpassing sequence-based baselines while maintaining high computa-
tional efficiency (∼1.13s per contract).
For future work, we plan to optimize the High-Fidelity feature extraction
process to close the performance gap with hybrid models like AME and extend
the framework to support heterogeneous blockchain platforms.
References
1. Atzei, N., Bartoletti, M., Cimoli, T.: A survey of attacks on ethereum smart
contracts. In: International conference on principles of security and trust. pp.
164–186. Springer (2017)
2. Feist, J., Grieco, G., Groce, A.: Slither: a static analysis framework for smart
contracts. In: 2019 IEEE/ACM 2nd International Workshop on Emerging Trends
in Software Engineering for Blockchain (WETSEB). pp. 8–15. IEEE (2019)
3. Gao, J., Huang, H., et al.: Smartembed: A tool for clone detection in smart contracts
using code embedding. In: Proceedings of the 2019 IEEE International Conference
on Software Maintenance and Evolution (ICSME). pp. 213–225 (2019)
4. Ghaleb, A., Pattabiraman, K.: How effective are smart contract analysis tools?
evaluating smart contract static analysis tools using bug injection. In: Proceedings
of the 29th ACM SIGSOFT International Symposium on Software Testing and
Analysis. pp. 154–165 (2020)
5. GNNSCVulDetector Contributors: Gnnscvuldetector: Smart contract vulner-
ability
detection
using
graph
neural
networks.
https://github.com/ufwt/
GNNSCVulDetector (2020), accessed: 2026-03-27
6. Hamilton, W.L., Ying, Z., Leskovec, J.: Inductive representation learning on large
graphs. In: Advances in Neural Information Processing Systems (NIPS). vol. 30,
pp. 1024–1034. Curran Associates, Inc. (2017), https://proceedings.neurips.cc/
paper/6703-inductive-representation-learning-on-large-graphs
7. Kasula, V.K., Yadulla, A.R., Yenugula, M., Konda, B.: Enhancing smart contract
vulnerability detection using graph-based deep learning approaches. In: 2024 In-
ternational Conference on Integrated Intelligence and Communication Systems
(ICIICS). pp. 1–6. IEEE (2024)
8. Liu, Z., Qian, P., Wang, X., Zhuang, Y., Qiu, L., Wang, X.: Combining graph
neural networks with expert knowledge for smart contract vulnerability detection.
IEEE Transactions on Knowledge and Data Engineering 35(2), 1296–1310 (2023).
https://doi.org/10.1109/TKDE.2021.3095196
10
Tan-Gia-Quoc Pham et al.
9. Luu, L., Chu, D.H., Olickel, H., Saxena, P., Hobor, A.: Making smart contracts
smarter. In: Proceedings of the 2016 ACM SIGSAC conference on computer and
communications security. pp. 254–269 (2016)
10. Mehar, M.I., Shier, A., Giambattista, A., Gong, E., Fletcher, G., Sanayhie, R., Kim,
H.M., Laskowski, M.: Understanding a revolutionary and flawed grand experiment
in blockchain: The dao attack. Journal of Cases on Information Technology (JCIT)
21(1), 19–32 (2019)
11. Mueller, B.: Smashing ethereum smart contracts: Mythril. HITB SECCONF (2018),
accessed: 2023-10-25
12. Qian, P., Liu, Z., He, Q., Zimmermann, R., Wang, X.: Towards automated and effec-
tive smart contract vulnerability detection: A graph-based deep learning approach.
IEEE Transactions on Dependable and Secure Computing 20(4), 2964–2977 (2023)
13. VNT Chain Team: Vntchain: A blockchain platform. https://github.com/
vntchain/go-vnt (2018), accessed: 2026-03-27
14. Wang, Y., Zhao, X., He, L., Zhen, Z., Chen, H.: Contractgnn: Ethereum smart
contract vulnerability detection based on vulnerability sub-graphs and graph neural
networks. IEEE Transactions on Network Science and Engineering (2024)
15. Wood, G.: Ethereum: A secure decentralised generalised transaction ledger.
Ethereum project yellow paper 151(2014), 1–32 (2014)
16. Zheng, Z., Xie, S., Dai, H.N., Chen, X., Wang, H.: An overview of blockchain
technology: Architecture, consensus, and future trends. In: 2017 IEEE international
congress on big data (BigData congress). pp. 557–564. IEEE (2017)
17. Zhou, Y., Liu, S., Si, J., Du, W., Liu, Y.: Devign: Effective vulnerability identifica-
tion by learning comprehensive program semantics via graph neural networks. In:
Advances in Neural Information Processing Systems (NeurIPS). vol. 32 (2019)
18. Zhuang, Y., Liu, Z., Qian, P., Liu, Q., Wang, X., He, Q.: Smart contract vulnerability
detection using graph neural network. In: Proceedings of the 29th International
Joint Conference on Artificial Intelligence (IJCAI). pp. 3283–3290 (2020)
